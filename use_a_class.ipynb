{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys, file and nav packages:\n",
    "import os\n",
    "import datetime as dt\n",
    "import csv\n",
    "\n",
    "# math packages:\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import datetime as dt \n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import kendalltau, pearsonr, spearmanr\n",
    "\n",
    "# charting:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import ticker\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "# from matplotlib.gridspec import GridSpec\n",
    "# from matplotlib import cm\n",
    "# from matplotlib.colors import ListedColormap, LinearSegmentedColormap, Colormap\n",
    "\n",
    "\n",
    "# home brew utitilties\n",
    "import resources.utilities.utility_functions as ut\n",
    "import resources.utilities.abundance_classes as ac\n",
    "\n",
    "# documenting\n",
    "from IPython.display import display, Markdown, Latex, HTML\n",
    "\n",
    "\n",
    "# returns the p_value for each test\n",
    "def kendall_pval(x,y):\n",
    "    return kendalltau(x,y)[1]\n",
    "\n",
    "def pearsonr_pval(x,y):\n",
    "    return pearsonr(x,y)[1]\n",
    "\n",
    "def spearmanr_pval(x,y):\n",
    "    return spearmanr(x,y)[1]\n",
    "\n",
    "# table kwargs\n",
    "table_k = dict(loc=\"top left\", bbox=(0,0,1,1), colWidths=[.5, .5], cellLoc='center')\n",
    "tablecenter_k = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='center')\n",
    "tabtickp_k = dict(axis='both', which='both', bottom=False, top=False, left=False, right=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "# chart kwargs\n",
    "title_k = {'loc':'left', 'pad':14, 'linespacing':1.5, 'fontsize':12}\n",
    "title_k14 = {'loc':'left', 'pad':16, 'linespacing':1.5, 'fontsize':14}\n",
    "xlab_k = {'labelpad':10, 'fontsize':12}\n",
    "ylab_k = {'labelpad':14, 'fontsize':14}\n",
    "\n",
    "\n",
    "# # use these to format date axis in charts\n",
    "# weeks = mdates.WeekdayLocator(byweekday=1, interval=4)\n",
    "# # onedayweek = mdates.DayLocator(bymonthday=1, interval=1)\n",
    "# # everytwoweeks = mdates.WeekdayLocator(byweekday=1, interval=4)\n",
    "\n",
    "# months = mdates.MonthLocator(bymonth=[3,6,9,12])\n",
    "# bimonthly = mdates.MonthLocator(bymonth=[1,3,5,7,9,11])\n",
    "# allmonths = mdates.MonthLocator()\n",
    "# wks_fmt = mdates.DateFormatter('%d')\n",
    "# mths_fmt = mdates.DateFormatter('%b')\n",
    "\n",
    "# map marker size:\n",
    "survey_data, location_data, code_defs, geo_data, output = ut.make_local_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion: Frequency, and amplititude of the top ten most observed litter items rhine source, rhine end\n",
    "\n",
    "bried description of why we are doing this\n",
    "\n",
    "\n",
    "#### slr data, dutch data\n",
    "\n",
    "brief description each project how the data was gathered\n",
    "\n",
    "#### abundance - codes that are commom to both regions\n",
    "\n",
    "discuss qauntities, pcs_m of the common codes in the top ten list\n",
    "\n",
    "#### abundance - codes that are not commom to both regions\n",
    "\n",
    "discuss qauntities, pcs_m of the codes that are not common in the top ten lists\n",
    "\n",
    "#### frequency - how often a code is reported\n",
    "\n",
    "dicuss the value of % found\n",
    "\n",
    "#### magnitude of the observation\n",
    "\n",
    "identify the elements that are a large percentage of what was identified and was identified frequently\n",
    "\n",
    "### Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some parameters:\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2017-12-31'\n",
    "\n",
    "# define a significant event:\n",
    "sig = .9\n",
    "one_minus_sig = (1-sig)\n",
    "\n",
    "# the surveys happen durring the following months\n",
    "months_of_surveys = [9,10,11,4,5,6]\n",
    "\n",
    "# name the folder:\n",
    "name_of_project = 'setup_class_methods'\n",
    "\n",
    "# formatting for chart titles\n",
    "startyearmonth = '{}/{}'.format(start_date[5:7], start_date[:4])\n",
    "endyearmonth = '{}/{}'.format(end_date[5:7], end_date[:4])\n",
    "\n",
    "# use this to store things:\n",
    "project_directory = ut.make_project_folder(output, name_of_project)\n",
    "\n",
    "# keep track of output\n",
    "files_generated = []\n",
    "figure_num = 0\n",
    "data_num = 0\n",
    "\n",
    "def add_output(**kwargs):\n",
    "    files_generated.append({'tag':kwargs['tag'], 'number':kwargs['figure_num'], 'file':kwargs['file'],'type':kwargs['a_type']})\n",
    "    if kwargs['a_type'] == 'data':\n",
    "        kwargs['data'].to_csv(F\"{kwargs['file']}.csv\", index=False)\n",
    "    else:\n",
    "        plt.savefig(F\"{kwargs['file']}.jpeg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data:\n",
    "data_methods={\"csv\":pd.read_csv, \"json\":ut.json_file_get}\n",
    "\n",
    "data_sources = {\n",
    "    \"swiss_beaches\":\"hammerdirt_beaches.csv\",\n",
    "    \"dutch_beaches\":\"dutch_beaches.csv\",\n",
    "}\n",
    "a_dir = F\"{location_data}\"\n",
    "\n",
    "\n",
    "swiss_beaches, dutch_beaches = ac.get_data_from_most_recent(data_sources, data_methods=data_methods, a_dir=a_dir)\n",
    "\n",
    "data_sources = {\n",
    "    \"dutch_codes\":\"new_dutch_codes.csv\",\n",
    "    \"swiss_codes\":\"swiss_codes_keyed_ospar.csv\"    \n",
    "}\n",
    "a_dir = F\"{code_defs}\"\n",
    "dutch_codes, swiss_codes = ac.get_data_from_most_recent(data_sources, data_methods=data_methods, a_dir=a_dir)\n",
    "\n",
    "data_sources = {\n",
    "    \"dutch_surveys\":\"dutch_surveys_h.csv\",\n",
    "    \"swiss_surveys\":\"aggregated_hd_surveys.csv\"    \n",
    "}\n",
    "a_dir = F\"{survey_data}\"\n",
    "dutch_surveys, swiss_surveys = ac.get_data_from_most_recent(data_sources, data_methods=data_methods, a_dir=a_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['location', 'date', 'loc_date', 'water_name', 'code', 'quantity',\n",
       "       'pcs_m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dutch_surveys.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>loc_date</th>\n",
       "      <th>water_name</th>\n",
       "      <th>code</th>\n",
       "      <th>quantity</th>\n",
       "      <th>pcs_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>waal1</td>\n",
       "      <td>2017-10-21</td>\n",
       "      <td>('waal1', datetime.date(2017, 10, 21))</td>\n",
       "      <td>Waal</td>\n",
       "      <td>plastic_6_packringen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>waal1</td>\n",
       "      <td>2017-10-21</td>\n",
       "      <td>('waal1', datetime.date(2017, 10, 21))</td>\n",
       "      <td>Waal</td>\n",
       "      <td>plastic_tassen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>waal1</td>\n",
       "      <td>2017-10-21</td>\n",
       "      <td>('waal1', datetime.date(2017, 10, 21))</td>\n",
       "      <td>Waal</td>\n",
       "      <td>plastic_kleine_plastic_tasjes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>waal1</td>\n",
       "      <td>2017-10-21</td>\n",
       "      <td>('waal1', datetime.date(2017, 10, 21))</td>\n",
       "      <td>Waal</td>\n",
       "      <td>plastic_drankflessen_groterdan_halveliter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>waal1</td>\n",
       "      <td>2017-10-21</td>\n",
       "      <td>('waal1', datetime.date(2017, 10, 21))</td>\n",
       "      <td>Waal</td>\n",
       "      <td>plastic_drankflessen_kleinerdan_halveliter</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location        date                                loc_date water_name  \\\n",
       "0    waal1  2017-10-21  ('waal1', datetime.date(2017, 10, 21))       Waal   \n",
       "1    waal1  2017-10-21  ('waal1', datetime.date(2017, 10, 21))       Waal   \n",
       "2    waal1  2017-10-21  ('waal1', datetime.date(2017, 10, 21))       Waal   \n",
       "3    waal1  2017-10-21  ('waal1', datetime.date(2017, 10, 21))       Waal   \n",
       "4    waal1  2017-10-21  ('waal1', datetime.date(2017, 10, 21))       Waal   \n",
       "\n",
       "                                         code  quantity  pcs_m  \n",
       "0                        plastic_6_packringen       0.0   0.00  \n",
       "1                              plastic_tassen       0.0   0.00  \n",
       "2               plastic_kleine_plastic_tasjes       2.0   0.02  \n",
       "3   plastic_drankflessen_groterdan_halveliter       0.0   0.00  \n",
       "4  plastic_drankflessen_kleinerdan_halveliter       1.0   0.01  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dutch_surveys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_beaches.set_index('slug', inplace=True)\n",
    "\n",
    "# key in the ospar id to the swiss surveys\n",
    "swiss_codes.set_index('code', inplace=True)\n",
    "\n",
    "# map that value\n",
    "os_mlw_map = swiss_codes.ospar_id\n",
    "\n",
    "# these are the water features that drain to the Rhine:\n",
    "water_names = ['Aare', 'Sihl', 'Reuss', 'Rhein', 'Limmat', 'Seez','Zurichsee','Quatre Cantons', 'Vorderrhein', 'Zugersee','Glatt', 'Goldach', 'Greifensee','Bodensee', 'Chriesbach', 'Emme', 'Neuenburgersee', 'Walensee' ]\n",
    "\n",
    "# format the date and slice the data \n",
    "swiss_surveys['date'] = pd.to_datetime(swiss_surveys['date'], format='%Y-%m-%d')\n",
    "swissDf = swiss_surveys[(swiss_surveys.date >= start_date)&(swiss_surveys.date <= end_date)].copy()\n",
    "\n",
    "\n",
    "\n",
    "# assign the water feature type to each result\n",
    "# make maps\n",
    "lakes = swiss_beaches.loc[swiss_beaches.water == 'l'].index\n",
    "rivers = swiss_beaches.loc[swiss_beaches.water == 'r'].index\n",
    "\n",
    "# apply maps:\n",
    "swissDf.loc[swissDf.location.isin(lakes), 'water'] = 'l'\n",
    "swissDf.loc[swissDf.location.isin(rivers), 'water'] = 'r'\n",
    "\n",
    "# apply os_mlw_map\n",
    "swissDf['ospar_id'] = swissDf.code.map(lambda x: os_mlw_map.loc[x] )\n",
    "\n",
    "# swap the code values\n",
    "swiss_surveys = swissDf[swissDf.water_name.isin(water_names)].drop('code', axis=1)\n",
    "swiss_surveys.rename(columns={'ospar_id':'code'}, inplace=True)\n",
    "\n",
    "# identify the swiss surveys as a group\n",
    "swiss_surveys['region'] = 'CH'\n",
    "\n",
    "# key the ospar code value into the dutch surveys\n",
    "current_codes = dutch_surveys.code.unique()\n",
    "\n",
    "# make a column to store the new code\n",
    "dutch_surveys['new_code'] = 0\n",
    "\n",
    "# make a map\n",
    "d_c_map = dutch_codes[['ID', 'parent_code']]\n",
    "d_c_map.set_index('ID', drop=True, inplace=True)\n",
    "\n",
    "# apply map\n",
    "for a_code in current_codes:\n",
    "    dutch_surveys.loc[dutch_surveys.code==a_code, 'new_code']= d_c_map.loc[a_code][0]\n",
    "\n",
    "# swap out the columns\n",
    "dutch_surveys.drop('code', inplace=True, axis=1)\n",
    "dutch_surveys.rename(columns={'new_code':'code'}, inplace=True)\n",
    "\n",
    "# identify the surveys as a whole\n",
    "dutch_surveys['region'] ='NL'\n",
    "\n",
    "# all the surveys in the netherlands are on rivers\n",
    "dutch_surveys['water']='r'\n",
    "\n",
    "surveys_all = pd.concat([swiss_surveys, dutch_surveys])\n",
    "surveys_all['date'] = pd.to_datetime(surveys_all['date'])\n",
    "surveys_all['month'] = surveys_all.date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surveys_all[surveys_all.code == 0].quantity.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harmonize data results for class methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "These are the results prior to applying geographic or temporal boundaries:\n",
      "\n",
      "region\n",
      "CH     51018.0\n",
      "NL    151006.0\n",
      "Name: quantity, dtype: float64\n",
      "\n",
      "\n",
      "Number of samples swiss surveys: 443, dutch survyes: 382\n"
     ]
    }
   ],
   "source": [
    "print(F\"\\nThese are the results prior to applying geographic or temporal boundaries:\\n\\n{surveys_all.groupby('region').quantity.sum()}\\n\")\n",
    "\n",
    "s_samps = swiss_surveys.loc_date.nunique()\n",
    "d_samps = dutch_surveys.loc_date.nunique()\n",
    "\n",
    "print(F\"\\nNumber of samples swiss surveys: {s_samps}, dutch survyes: {d_samps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'levels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4bf33432668d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mthese_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'loc_date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'location'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'water_name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'water'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'region'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPreprocessData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurveys_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdutch_beaches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthese_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthese_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dev/collaborate/rhinecode/resources/utilities/abundance_classes.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, beaches, these_cols, foams, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfoams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfoams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeaches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeaches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'levels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp_variables'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocations_in_use\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'levels'"
     ]
    }
   ],
   "source": [
    "# these are the columns that the class method expects to see:\n",
    "these_cols = ['loc_date', 'location', 'water_name','water', 'date','month', 'region']\n",
    "\n",
    "a = ac.PreprocessData(surveys_all, dutch_beaches,these_cols=these_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_cols = ['region','water_name','water','loc_date', 'location', 'date', 'month']\n",
    "\n",
    "clas_kwargs = dict(\n",
    "#     code_group_data=group_names_locations,\n",
    "#     new_code_group=frag_plas,\n",
    "#     levels=levels,\n",
    "#     catchment_features=bassin,\n",
    "    end_date=end_date,\n",
    "    start_date=start_date,\n",
    "#     code_group_loc=output,\n",
    "    catchment_cols=catchment_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ac.CatchmentArea(a.processed, swiss_beaches, **clas_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographic spread and frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# wfoams = ['G81', 'G82', 'G117']\n",
    "# yfoams = ['G74', 'G73', 'G75']\n",
    "# pand = ['G900', 'G901', 'G902']\n",
    "# candy = ['G30']\n",
    "# personal_hygiene = dfCodes.loc[dfCodes.source == 'Personal hygiene'].index.to_numpy()\n",
    "# tobacco_codes = dfCodes.loc[dfCodes.source == 'Tobacco'].index.to_numpy()\n",
    "\n",
    "# make a copy of the data to work with\n",
    "\n",
    "# eliminate the OSPAR code 117, these objects were not counted in Switzerland 2017\n",
    "som_data = b.bassin_data[b.bassin_data.code != 117].copy()\n",
    "\n",
    "# use only the data that was gathered in the following months\n",
    "som_data = som_data.loc[som_data.month.isin(months_of_surveys)]\n",
    "\n",
    "data_num+=1\n",
    "# 'tag':kwargs['tag'], 'number':kwargs['figure_num'], 'file':kwargs['file'],'type':kwargs['a_type']\n",
    "a_tag = 'data used for all calculations'\n",
    "\n",
    "file = F\"{project_directory}/all_data_used.csv\"\n",
    "a_type='data'\n",
    "\n",
    "add_output(tag=a_tag, figure_num=data_num, a_type=a_type, file=file, data=som_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F\"\\nThe data is limited to all samples on or after {start_date} and up to {end_date} for the following months:\\n{months_of_surveys}\")\n",
    "\n",
    "number_of_samples = len(som_data.loc_date.unique())\n",
    "number_of_locations = len(som_data.location.unique())\n",
    "number_of_objects = som_data.quantity.sum()\n",
    "number_of_features = len(som_data.water_name.unique())\n",
    "print(F\"The number of samples, number of locations, the total number of objects and the number of features:\\n\\n1. number of samples: {number_of_samples}\\n2. number of locations: {number_of_locations}\\n3. number of objects: {number_of_objects}\\n4. number of features: {number_of_features}\\n\")\n",
    "\n",
    "num_samples_country = som_data.groupby('region').loc_date.nunique()\n",
    "q_per_country = som_data.groupby('region').quantity.sum()\n",
    "\n",
    "print(F\"\\nThe number of samples per country:\\n\\n{num_samples_country}\\n\")\n",
    "print(F\"\\nThe number of objects identified per country:\\n\\n{q_per_country}\\n\")\n",
    "# print(num_samples_country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(F\"There are {len(som_data.water_name.unique())} different water features:\\n\\n{som_data.groupby('region').water_name.unique().to_numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of locations by feature\n",
    "num_loc_feature = som_data.groupby('water_name', as_index=False).location.nunique()\n",
    "num_loc_feature_d = som_data.groupby('water_name', as_index=False).agg({'location':'nunique', 'loc_date':'nunique'})\n",
    "num_loc_feature_d.rename(columns={'location':'# of locations', 'loc_date':'# of samples'}, inplace=True)\n",
    "print(F\"The number of locations and the number of samples per location:\\n\\n{num_loc_feature_d.set_index('water_name')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "som_data['fail'] = som_data.quantity > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dutch_top_ten = som_data[som_data.region == 'NL'].groupby(['code'], as_index=False).quantity.sum().sort_values(by='quantity',ascending=False)\n",
    "dutch_total = dutch_top_ten.quantity.sum()\n",
    "dutch_top_ten['% of total'] = dutch_top_ten.quantity/dutch_total\n",
    "\n",
    "\n",
    "swiss_top_ten = som_data[som_data.region == 'CH'].groupby(['code'], as_index=False).quantity.sum().sort_values(by='quantity',ascending=False)\n",
    "swiss_total = swiss_top_ten.quantity.sum()\n",
    "swiss_top_ten['% of total'] = swiss_top_ten.quantity/swiss_total\n",
    "\n",
    "print(F\"\\nThe swiss top ten:\\n\\n{swiss_top_ten.sort_values(by='quantity', ascending=False)[:10]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(F\"\\nThe dutch top ten:\\n\\n{dutch_top_ten.sort_values(by='quantity', ascending=False)[:10]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtt_c = dutch_top_ten[:10].code.values\n",
    "\n",
    "\n",
    "stt_c = swiss_top_ten[:10].code.values\n",
    "\n",
    "\n",
    "# the top ten for each region\n",
    "coi_d = dutch_top_ten[dutch_top_ten.code.isin(dtt_c)]\n",
    "coi_s = swiss_top_ten[swiss_top_ten.code.isin(stt_c)]\n",
    "\n",
    "# the combined top ten\n",
    "combined = list(set(stt_c)|set(dtt_c))\n",
    "\n",
    "print(F\"\\nThese are the codes that are in both top ten lists:\\n\\n{combined}\\n\")\n",
    "\n",
    "print(F\"\\nThese are the codes that are shared:\\n\\n{list(set(dtt_c) & set(stt_c))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "coi_all = som_data[som_data.code.isin(combined)].copy()\n",
    "\n",
    "# group all the records by loc_date and code\n",
    "coi_all = coi_all.groupby(['loc_date','region','water', 'water_name', 'location', 'code'], as_index=False).agg({'quantity':'sum', 'pcs_m':'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "a_key = dutch_codes[['parent_code', 'description']].drop_duplicates('parent_code', keep='first').set_index('parent_code', drop=True)\n",
    "\n",
    "print(F\"\\nThese are the code definitions:\\n\\n{a_key.loc[combined]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def add_new_label(ax_get_labels, key):\n",
    "    return [key.loc[int(x.get_text())][0] for x in ax_get_labels]\n",
    "coi_all['description'] = coi_all.code.map(lambda x:a_key.loc[4][0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# mark all results that are greater than zero as fail = true:\n",
    "coi_all['fail'] = coi_all.quantity > 0\n",
    "\n",
    "\n",
    "# get the average value for pcs_m, the sum of quantity and fail, and the count of loc_date for each code\n",
    "coi_wt = coi_all.groupby(['water_name', 'code', 'description'], as_index=False).agg({'quantity':'sum', 'pcs_m':'mean', 'fail':'sum', 'loc_date':'count'})\n",
    "coi_lr = coi_all.groupby(['water', 'code', 'description'], as_index=False).agg({'quantity':'sum', 'pcs_m':'mean', 'fail':'sum', 'loc_date':'count'})\n",
    "coi_at = coi_all.groupby(['region',  'code', 'description'], as_index=False).agg({'quantity':'sum', 'pcs_m':'mean', 'fail':'sum', 'loc_date':'count'})\n",
    "\n",
    "# get the quantity as a % of the total\n",
    "for a_region in coi_at.region.unique():\n",
    "    coi_at.loc[coi_at.region==a_region, '% of total'] = coi_at.quantity/coi_at[coi_at.region==a_region].quantity.sum()\n",
    "for a_name in coi_wt.water_name.unique():\n",
    "    coi_wt.loc[coi_wt.water_name==a_name, '% of total'] = coi_wt.quantity/coi_wt[coi_wt.water_name==a_name].quantity.sum()\n",
    "for a_name in coi_lr.water.unique():\n",
    "    coi_lr.loc[coi_lr.water==a_name, '% of total'] = coi_lr.quantity/coi_lr[coi_lr.water==a_name].quantity.sum()\n",
    "\n",
    "\n",
    "# get the rate at which the oobject was found\n",
    "for a_region in coi_at.region.unique():\n",
    "    coi_at.loc[coi_at.region==a_region, '% found'] = coi_at.fail/coi_at[coi_at.region==a_region].loc_date\n",
    "for a_name in coi_wt.water_name.unique():\n",
    "    coi_wt.loc[coi_wt.water_name==a_name, '% found'] = coi_wt.fail/coi_wt[coi_wt.water_name==a_name].loc_date\n",
    "for a_name in coi_lr.water.unique():\n",
    "    coi_lr.loc[coi_lr.water==a_name, '% found'] = coi_lr.fail/coi_lr[coi_lr.water==a_name].loc_date\n",
    "\n",
    "    # the product of % of total * % found\n",
    "coi_at['magnitude'] = coi_at['% found']*coi_at['% of total']\n",
    "coi_wt['magnitude'] = coi_wt['% found']*coi_wt['% of total']\n",
    "coi_lr['magnitude'] = coi_lr['% found']*coi_lr['% of total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# just the rivers\n",
    "coi_just_rivers = coi_all[coi_all.water == 'r'].copy()\n",
    "coi_jr_regio = coi_just_rivers.groupby(['region',  'code'], as_index=False).agg({'quantity':'sum', 'pcs_m':'mean', 'fail':'sum', 'loc_date':'count'})\n",
    "coi_jr = coi_just_rivers.groupby(['water_name', 'code'], as_index=False).agg({'quantity':'sum', 'pcs_m':'mean', 'fail':'sum', 'loc_date':'count'})\n",
    "\n",
    "for a_region in coi_jr_regio.region.unique():\n",
    "    coi_jr_regio.loc[coi_jr_regio.region==a_region, '% of total'] = coi_jr_regio.quantity/coi_jr_regio[coi_jr_regio.region==a_region].quantity.sum()\n",
    "for a_name in coi_jr.water_name.unique():\n",
    "    coi_jr.loc[coi_jr.water_name==a_name, '% of total'] = coi_jr.quantity/coi_jr[coi_jr.water_name==a_name].quantity.sum()\n",
    "# coi_jr_regio['% of total'] = coi_jr_regio.quantity/coi_jr_regio.quantity.sum()\n",
    "# coi_jr['% of total'] = coi_jr.quantity/coi_jr.quantity.sum()\n",
    "\n",
    "# get the rate at which the oobject was found\n",
    "\n",
    "for a_region in coi_jr_regio.region.unique():\n",
    "    coi_jr_regio.loc[coi_jr_regio.region==a_region, '% found'] = coi_jr_regio.fail/coi_jr_regio[coi_jr_regio.region==a_region].loc_date\n",
    "for a_name in coi_jr.water_name.unique():\n",
    "    coi_jr.loc[coi_jr.water_name==a_name, '% found'] = coi_jr.fail/coi_jr[coi_jr.water_name==a_name].loc_date\n",
    "# coi_jr_regio['% found'] = coi_jr_regio.fail/coi_jr_regio.loc_date\n",
    "# coi_jr['% found'] = coi_jr.fail/coi_jr.loc_date\n",
    "\n",
    "# the product of % of total * % found\n",
    "coi_jr_regio['magnitude'] = coi_jr_regio['% found']*coi_jr_regio['% of total']\n",
    "coi_jr['magnitude'] = coi_jr['% found']*coi_jr['% of total']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nResults grouped by country:\\n\\n\")\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(10,12))\n",
    "\n",
    "heat_map_data = coi_at[['region', 'code', '% of total']].pivot(index='code', columns='region')\n",
    "heat_map_data.columns = heat_map_data.columns.get_level_values(1)\n",
    "heat_map_data = heat_map_data.sort_values(by='NL', ascending=False )\n",
    "sns.heatmap(data=heat_map_data, cmap='rocket_r', linewidth=.1, ax=axs[0,0])\n",
    "axs[0,0].tick_params(axis='y', labelrotation=0)\n",
    "# axs[0,0].set_yticklabels(add_new_label(axs[0,0].get_yticklabels(), a_key))\n",
    "axs[0,0].set_ylabel(\"\", **ylab_k)\n",
    "axs[0,0].set_xlabel(\"\")\n",
    "axs[0,0].set_title(\"% of total by country\", **title_k)\n",
    "\n",
    "heat_map_data = coi_at[['region', 'code', 'pcs_m']].pivot(index='code', columns='region')\n",
    "heat_map_data.columns = heat_map_data.columns.get_level_values(1)\n",
    "heat_map_data = heat_map_data.sort_values(by='NL', ascending=False )\n",
    "sns.heatmap(data=heat_map_data, cmap='rocket_r', linewidth=.1, ax=axs[0,1])\n",
    "axs[0,1].tick_params(axis='y', labelrotation=0)\n",
    "axs[0,1].set_ylabel(\"\", **ylab_k)\n",
    "axs[0,1].set_xlabel(\"\")\n",
    "axs[0,1].set_title(\"average pieces per meter\", **title_k)\n",
    "\n",
    "heat_map_data = coi_at[['region', 'code', '% found']].pivot(index='code', columns='region')\n",
    "heat_map_data.columns = heat_map_data.columns.get_level_values(1)\n",
    "heat_map_data = heat_map_data.sort_values(by='NL', ascending=False )\n",
    "sns.heatmap(data=heat_map_data, cmap='rocket_r', linewidth=.1, ax=axs[1,0])\n",
    "axs[1,0].tick_params(axis='y', labelrotation=0)\n",
    "axs[1,0].set_ylabel(\"\", **ylab_k)\n",
    "axs[1,0].set_xlabel(\"\")\n",
    "axs[1,0].set_title(\"% found\", **title_k)\n",
    "\n",
    "heat_map_data = coi_at[['region', 'code', 'magnitude']].pivot(index='code', columns='region')\n",
    "heat_map_data.columns = heat_map_data.columns.get_level_values(1)\n",
    "heat_map_data = heat_map_data.sort_values(by='NL', ascending=False )\n",
    "sns.heatmap(data=heat_map_data, cmap='rocket_r', linewidth=.1, ax=axs[1,1])\n",
    "axs[1,1].tick_params(axis='y', labelrotation=0)\n",
    "axs[1,1].set_ylabel(\"\", **ylab_k)\n",
    "axs[1,1].set_xlabel(\"\")\n",
    "axs[1,1].set_title(\"(% of total) * (% found)\", **title_k)\n",
    "\n",
    "axs[0,0].set_yticklabels(add_new_label(axs[0,0].get_yticklabels(), a_key))\n",
    "axs[0,1].set_yticklabels(add_new_label(axs[0,1].get_yticklabels(), a_key))\n",
    "axs[1,0].set_yticklabels(add_new_label(axs[1,0].get_yticklabels(), a_key))\n",
    "axs[1,1].set_yticklabels(add_new_label(axs[1,1].get_yticklabels(), a_key))\n",
    "\n",
    "# plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=.5, hspace=.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=None, bottom=None, right=.9, top=None, wspace=.99, hspace=.2)\n",
    "file_name = F\"{project_directory}/combined_top_ten_country.jpg\"\n",
    "plt.savefig(file_name, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nResults grouped by lake or river both countries:\\n\\n\")\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(10,12))\n",
    "\n",
    "heat_map_data = coi_lr[['water', 'code', '% of total']].pivot(index='code', columns='water')\n",
    "heat_map_data.columns = heat_map_data.columns.get_level_values(1)\n",
    "heat_map_data = heat_map_data.sort_values(by='r', ascending=False )\n",
    "sns.heatmap(data=heat_map_data, cmap='rocket_r', linewidth=.1, ax=axs[0,0])\n",
    "axs[0,0].tick_params(axis='y', labelrotation=0)\n",
    "axs[0,0].set_ylabel(\"\", **ylab_k)\n",
    "axs[0,0].set_xlabel(\"\")\n",
    "axs[0,0].set_title(\"% of total by lake of river\", **title_k)\n",
    "\n",
    "heat_map_data = coi_lr[['water', 'code', 'pcs_m']].pivot(index='code', columns='water')\n",
    "heat_map_data.columns = heat_map_data.columns.get_level_values(1)\n",
    "heat_map_data = heat_map_data.sort_values(by='r', ascending=False )\n",
    "sns.heatmap(data=heat_map_data, cmap='rocket_r', linewidth=.1, ax=axs[0,1])\n",
    "axs[0,1].tick_params(axis='y', labelrotation=0)\n",
    "axs[0,1].set_ylabel(\"\", **ylab_k)\n",
    "axs[0,1].set_xlabel(\"\")\n",
    "axs[0,1].set_title(\"average pieces per meter\", **title_k)\n",
    "\n",
    "heat_map_data = coi_lr[['water', 'code', '% found']].pivot(index='code', columns='water')\n",
    "heat_map_data.columns = heat_map_data.columns.get_level_values(1)\n",
    "heat_map_data = heat_map_data.sort_values(by='r', ascending=False )\n",
    "sns.heatmap(data=heat_map_data, cmap='rocket_r', linewidth=.1, ax=axs[1,0])\n",
    "axs[1,0].tick_params(axis='y', labelrotation=0)\n",
    "axs[1,0].set_ylabel(\"\", **ylab_k)\n",
    "axs[1,0].set_xlabel(\"\")\n",
    "axs[1,0].set_title(\"% found\", **title_k)\n",
    "\n",
    "heat_map_data = coi_lr[['water', 'code', 'magnitude']].pivot(index='code', columns='water')\n",
    "heat_map_data.columns = heat_map_data.columns.get_level_values(1)\n",
    "heat_map_data = heat_map_data.sort_values(by='r', ascending=False )\n",
    "sns.heatmap(data=heat_map_data, cmap='rocket_r', linewidth=.1, ax=axs[1,1])\n",
    "axs[1,1].tick_params(axis='y', labelrotation=0)\n",
    "axs[1,1].set_ylabel(\"\", **ylab_k)\n",
    "axs[1,1].set_xlabel(\"\")\n",
    "axs[1,1].set_title(\"(% of total) * (% found)\", **title_k)\n",
    "\n",
    "axs[0,0].set_yticklabels(add_new_label(axs[0,0].get_yticklabels(), a_key))\n",
    "axs[0,1].set_yticklabels(add_new_label(axs[0,1].get_yticklabels(), a_key))\n",
    "axs[1,0].set_yticklabels(add_new_label(axs[1,0].get_yticklabels(), a_key))\n",
    "axs[1,1].set_yticklabels(add_new_label(axs[1,1].get_yticklabels(), a_key))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=None, bottom=None, right=.9, top=None, wspace=.99, hspace=.2)\n",
    "file_name = F\"{project_directory}/combined_top_ten_lake_river.jpg\"\n",
    "plt.savefig(file_name, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nSwiss rivers versus dutch rivers:\\n\\n\")\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(10,12))\n",
    "\n",
    "heat_map_data = coi_jr_regio[['region', 'code', '% of total']].pivot(index='code', columns='region')\n",
    "heat_map_data.columns = heat_map_data.columns.get_level_values(1)\n",
    "heat_map_data = heat_map_data.sort_values(by='NL', ascending=False )\n",
    "sns.heatmap(data=heat_map_data, cmap='rocket_r', linewidth=.1, ax=axs[0,0])\n",
    "axs[0,0].tick_params(axis='y', labelrotation=0)\n",
    "axs[0,0].set_ylabel(\"\", **ylab_k)\n",
    "axs[0,0].set_xlabel(\"\")\n",
    "axs[0,0].set_title(\"% of total \", **title_k)\n",
    "\n",
    "heat_map_data = coi_jr_regio[['region', 'code', 'pcs_m']].pivot(index='code', columns='region')\n",
    "heat_map_data.columns = heat_map_data.columns.get_level_values(1)\n",
    "heat_map_data = heat_map_data.sort_values(by='NL', ascending=False )\n",
    "sns.heatmap(data=heat_map_data, cmap='rocket_r', linewidth=.1, ax=axs[0,1])\n",
    "axs[0,1].tick_params(axis='y', labelrotation=0)\n",
    "axs[0,1].set_ylabel(\"\", **ylab_k)\n",
    "axs[0,1].set_xlabel(\"\")\n",
    "axs[0,1].set_title(\"average pieces per meter\", **title_k)\n",
    "\n",
    "heat_map_data = coi_jr_regio[['region', 'code', '% found']].pivot(index='code', columns='region')\n",
    "heat_map_data.columns = heat_map_data.columns.get_level_values(1)\n",
    "heat_map_data = heat_map_data.sort_values(by='NL', ascending=False )\n",
    "sns.heatmap(data=heat_map_data, cmap='rocket_r', linewidth=.1, ax=axs[1,0])\n",
    "axs[1,0].tick_params(axis='y', labelrotation=0)\n",
    "axs[1,0].set_ylabel(\"\", **ylab_k)\n",
    "axs[1,0].set_xlabel(\"\")\n",
    "axs[1,0].set_title(\"% found\", **title_k)\n",
    "\n",
    "heat_map_data = coi_jr_regio[['region', 'code', 'magnitude']].pivot(index='code', columns='region')\n",
    "heat_map_data.columns = heat_map_data.columns.get_level_values(1)\n",
    "heat_map_data = heat_map_data.sort_values(by='NL', ascending=False )\n",
    "sns.heatmap(data=heat_map_data, cmap='rocket_r', linewidth=.1, ax=axs[1,1])\n",
    "axs[1,1].tick_params(axis='y', labelrotation=0)\n",
    "axs[1,1].set_ylabel(\"\", **ylab_k)\n",
    "axs[1,1].set_xlabel(\"\")\n",
    "axs[1,1].set_title(\"(% of total) * (% found)\", **title_k)\n",
    "\n",
    "axs[0,0].set_yticklabels(add_new_label(axs[0,0].get_yticklabels(), a_key))\n",
    "axs[0,1].set_yticklabels(add_new_label(axs[0,1].get_yticklabels(), a_key))\n",
    "axs[1,0].set_yticklabels(add_new_label(axs[1,0].get_yticklabels(), a_key))\n",
    "axs[1,1].set_yticklabels(add_new_label(axs[1,1].get_yticklabels(), a_key))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=None, bottom=None, right=.9, top=None, wspace=.99, hspace=.2)\n",
    "file_name = F\"{project_directory}/combined_swiss_vs_dutch.jpg\"\n",
    "plt.savefig(file_name, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n% of total by water feature:\\n\\n\")\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(8,8))\n",
    "\n",
    "heat_map_data = coi_wt[['water_name', 'code', '% of total']].pivot(index='water_name', columns='code')\n",
    "\n",
    "\n",
    "sns.heatmap(data=heat_map_data, cmap='rocket_r', ax=axs, linewidth=.1)\n",
    "axs.tick_params(axis='y', labelrotation=0)\n",
    "axs.set_ylabel(\"\", **ylab_k)\n",
    "axs.set_xlabel(\"\")\n",
    "axs.set_title(\"% of total by water feature\", **title_k)\n",
    "labels = axs.get_xticklabels()\n",
    "labels = [x.get_text().split('-')[-1] for x in labels]\n",
    "axs.set_xticklabels(labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "file_name = F\"{project_directory}/top_ten_percent_feature.jpg\"\n",
    "plt.savefig(file_name, dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\naverage pieces per meter by water feature:\\n\\n\")\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(8,8))\n",
    "\n",
    "heat_map_data = coi_wt[['water_name', 'code', 'pcs_m']].pivot(index='water_name', columns='code')\n",
    "\n",
    "\n",
    "sns.heatmap(data=heat_map_data, cmap='rocket_r', linewidth=.1, ax=axs)\n",
    "axs.tick_params(axis='y', labelrotation=0)\n",
    "axs.set_ylabel(\"\", **ylab_k)\n",
    "axs.set_xlabel(\"\")\n",
    "axs.set_title(\"average pieces per meter by water feature\", **title_k)\n",
    "labels = axs.get_xticklabels()\n",
    "labels = [x.get_text().split('-')[-1] for x in labels]\n",
    "axs.set_xticklabels(labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "file_name = F\"{project_directory}/top_ten_pcsm_feature.jpg\"\n",
    "plt.savefig(file_name, dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n% of surveys where at least one was found:\\n\\n\")\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(8,8))\n",
    "\n",
    "heat_map_data = coi_wt[['water_name', 'code', '% found']].pivot(index='water_name', columns='code')\n",
    "\n",
    "\n",
    "sns.heatmap(data=heat_map_data, cmap='rocket_r',linewidth=.1, ax=axs)\n",
    "axs.tick_params(axis='y', labelrotation=0)\n",
    "axs.set_ylabel(\"\", **ylab_k)\n",
    "axs.set_xlabel(\"\")\n",
    "axs.set_title(\"% of surveys where at least one was found by water feature\", **title_k)\n",
    "labels = axs.get_xticklabels()\n",
    "labels = [x.get_text().split('-')[-1] for x in labels]\n",
    "axs.set_xticklabels(labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "file_name = F\"{project_directory}/more_than_one_found_survey.jpg\"\n",
    "plt.savefig(file_name, dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n% of magnitude:\\n\\n\")\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(8,8))\n",
    "\n",
    "heat_map_data = coi_wt[['water_name', 'code', 'magnitude']].pivot(index='water_name', columns='code')\n",
    "\n",
    "\n",
    "sns.heatmap(data=heat_map_data, cmap='rocket_r',linewidth=.1, ax=axs)\n",
    "axs.tick_params(axis='y', labelrotation=0)\n",
    "axs.set_ylabel(\"\", **ylab_k)\n",
    "axs.set_xlabel(\"\")\n",
    "axs.set_title(\"magnitude of result by water feature\", **title_k)\n",
    "labels = axs.get_xticklabels()\n",
    "labels = [x.get_text().split('-')[-1] for x in labels]\n",
    "axs.set_xticklabels(labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "file_name = F\"{project_directory}/features_magnitude.jpg\"\n",
    "plt.savefig(file_name, dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abundance: number of objects and percent of total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"The files generated by this workbook:\\n\")\n",
    "files_generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hopefully that just worked for you\n",
    "\n",
    "if not contact analyst@hammerdirt.ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
