{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### general tenplate\n",
    "\n",
    "\n",
    "Fetches data from the local source and esyablishes the following variables:\n",
    "\n",
    "1. dutch_codes\n",
    "2. swiss_codes\n",
    "3. dutch_surveys\n",
    "4. swiss_surveys\n",
    "5. swiss_beaches\n",
    "\n",
    "\n",
    "Establishes directory variables for fetching and putting to all subdirectories:\n",
    "\n",
    "1. data\n",
    "2. beaches\n",
    "3. codes\n",
    "4. geo\n",
    "5. output\n",
    "\n",
    "provides a script to update the remote data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys things\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# networks\n",
    "import requests\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "import resources.utilities.utility_functions as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look for resources here\n",
      "\n",
      "resources/surveydata resources/locationdata resources/mlwcodedefs resources/geodata output\n"
     ]
    }
   ],
   "source": [
    "# get folder extesions\n",
    "data, beaches, codes, geo, output=ut.make_local_paths()\n",
    "print(\"look for resources here\\n\")\n",
    "print(data, beaches, codes, geo, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code data\n",
    "dutch_codes = pd.read_csv(codes+'/dutch_codes.csv')\n",
    "swiss_codes = pd.read_csv(codes+'/swiss_codes.csv')\n",
    "# this list was recieved from david fleet: one of the authors of the monitoring guide\n",
    "joint_list = pd.read_csv(F\"{codes}/jointcodes/ospar_mlw_fleet.csv\")\n",
    "\n",
    "# housekeeping\n",
    "dutch_codes.fillna(0, inplace=True)\n",
    "dutch_codes.rename(columns={'OSPAR_ID':'ospar_id', 'Description':'description'}, inplace=True)\n",
    "swiss_codes.rename(columns={'ospar_code':'ospar_id'}, inplace=True)\n",
    "swiss_codes.drop('Unnamed: 0', axis=1,inplace=True)\n",
    "\n",
    "# survey_data\n",
    "dutch_surveys = pd.read_csv(data+'/dataset_macrolitter_NL.csv')\n",
    "\n",
    "# use the aggregated hd data. This accounts for the custom codes used in Switzerland\n",
    "swiss_surveys = pd.read_csv(data+'/aggregated_hd_surveys.csv')\n",
    "\n",
    "# location data\n",
    "swiss_beaches = pd.read_csv(beaches+'/hammerdirt_beaches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns from cleaned up dutch data\n",
      "\n",
      "Index(['ID', 'description', 'category', 'ospar_id'], dtype='object')\n",
      "\n",
      "Columns from cleaned up swiss data\n",
      "\n",
      "Index(['code', 'material', 'description', 'source', 'source_two',\n",
      "       'source_three', 'parent_code', 'direct', 'single_use', 'micro',\n",
      "       'ospar_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns from cleaned up dutch data\\n\")\n",
    "print(dutch_codes.columns)\n",
    "\n",
    "print(\"\\nColumns from cleaned up swiss data\\n\")\n",
    "print(swiss_codes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the OSPAR code list from the dutch data.\n",
      "\n",
      "OSPAR codes that could not be typed to 'int' were counted as 0.\n",
      "\n",
      "Any code with an ospar value of 0 was excluded\n",
      "\n",
      "\n",
      "[   1    2    3    4    5    6    7    9   10   13   14   15   16   20\n",
      "   21   24   25  113   31   32   33   36   38   40   42   43   44  117\n",
      "   46   48 1172  462   47   22   19  472  212  481   11   39    8   17\n",
      "   35   49   52   53   54   55   57   59   60   61   63   64   65   66\n",
      "   67   62   68   69   72   73   74   75   81   78   79   83   77   84\n",
      "   88   76   86   80   82  120   89   90   91   92   93   98  982  102\n",
      "   97   99   18  100  101  103  104  105]\n",
      "\n",
      "These are the detail codes used to better define the object:\n",
      "\n",
      "[  4 117  46   6  47  22  19   2  43  38  39  62  67  81 102   1]\n"
     ]
    }
   ],
   "source": [
    "# process the ducth codes:\n",
    "# identify codes that are common to both 'ospar_id' columns\n",
    "dutch_codes['parent_code'] = dutch_codes.ospar_id.round(0)\n",
    "dutch_codes['parent_code'] = dutch_codes['parent_code'].astype('int') \n",
    "dutch_codes['child_code'] = dutch_codes.ospar_id - dutch_codes.parent_code\n",
    "\n",
    "\n",
    "# the number of child codes:\n",
    "child_codes = dutch_codes.loc[dutch_codes.child_code > 0]\n",
    "ccodes = child_codes.parent_code.unique()\n",
    "\n",
    "# all the codes with no remainder:\n",
    "parent_codes = dutch_codes.loc[dutch_codes.child_code == 0]\n",
    "pcodes = parent_codes.parent_code.unique()\n",
    "\n",
    "# all the dutch codes that are not child codes:\n",
    "dcodesall = dutch_codes.parent_code.unique()\n",
    "\n",
    "print(\"\"\"\n",
    "This is the OSPAR code list from the dutch data.\\n\n",
    "OSPAR codes that could not be typed to 'int' were counted as 0.\\n\n",
    "Any code with an ospar value of 0 was excluded\\n\n",
    "\"\"\")\n",
    "print(dutch_codes['parent_code'].unique())\n",
    "print(F\"\\nThese are the detail codes used to better define the object:\\n\\n{ccodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the mlw/ospar code list from the swiss codes.\n",
      "\n",
      "OSPAR codes that could not be typed to 'int' were counted as 0.\n",
      "\n",
      "Any code with an ospar value of 0 was excluded\n",
      "\n",
      "\n",
      "[('G213', 181) ('G214', 111) ('G135', 54) ('G137', 54) ('G138', 57)\n",
      " ('G140', 56) ('G141', 55) ('G144', 100) ('G145', 59) ('G200', 91)\n",
      " ('G201', 93) ('G204', 94) ('G210', 96) ('G175', 78) ('G176', 82)\n",
      " ('G177', 81) ('G178', 77) ('G181', 89) ('G182', 80) ('G188', 89)\n",
      " ('G194', 89) ('G150', 118) ('G151', 62) ('G152', 63) ('G153', 67)\n",
      " ('G155', 67) ('G1', 1) ('G10', 6) ('G100', 103) ('G11', 7) ('G12', 7)\n",
      " ('G13', 12) ('G20', 15) ('G21', 15) ('G22', 15) ('G24', 15) ('G25', 48)\n",
      " ('G26', 16) ('G27', 64) ('G28', 17) ('G29', 18) ('G3', 2) ('G30', 19)\n",
      " ('G31', 19) ('G32', 20) ('G33', 21) ('G34', 22) ('G35', 22) ('G36', 23)\n",
      " ('G38', 40) ('G4', 3) ('G40', 25) ('G41', 113) ('G43', 114) ('G6', 11)\n",
      " ('G66', 39) ('G67', 40) ('G7', 4) ('G73', 45) ('G74', 45) ('G75', 117)\n",
      " ('G76', 46) ('G78', 117) ('G79', 46) ('G8', 4) ('G81', 117) ('G82', 46)\n",
      " ('G87', 48) ('G88', 48) ('G9', 5) ('G91', 91) ('G93', 48) ('G95', 98)\n",
      " ('G96', 99) ('G98', 102) ('G125', 49) ('G133', 97) ('G211', 105)\n",
      " ('G161', 69) ('G165', 72)]\n",
      "\n",
      "These are the mlw codes that do not have a valid OSPAR code from the swiss list:\n",
      "\n",
      "[('G136', 0) ('G139', 0) ('G142', 0) ('G143', 0) ('G202', 0) ('G203', 0)\n",
      " ('G205', 0) ('G208', 0) ('G174', 0) ('G179', 0) ('G180', 0) ('G185', 0)\n",
      " ('G186', 0) ('G190', 0) ('G191', 0) ('G193', 0) ('G195', 0) ('G197', 0)\n",
      " ('G198', 0) ('G199', 0) ('G146', 0) ('G147', 0) ('G148', 0) ('G149', 0)\n",
      " ('G154', 0) ('G156', 0) ('G157', 0) ('G158', 0) ('G101', 0) ('G102', 0)\n",
      " ('G103', 0) ('G104', 0) ('G105', 0) ('G106', 0) ('G107', 0) ('G108', 0)\n",
      " ('G109', 0) ('G111', 0) ('G112', 0) ('G113', 0) ('G114', 0) ('G115', 0)\n",
      " ('G116', 0) ('G117', 0) ('G118', 0) ('G119', 0) ('G122', 0) ('G123', 0)\n",
      " ('G124', 0) ('G14', 0) ('G17', 0) ('G19', 0) ('G2', 0) ('G23', 0)\n",
      " ('G37', 0) ('G39', 0) ('G48', 0) ('G49', 0) ('G5', 0) ('G50', 0)\n",
      " ('G52', 0) ('G53', 0) ('G55', 0) ('G56', 0) ('G59', 0) ('G60', 0)\n",
      " ('G61', 0) ('G62', 0) ('G63', 0) ('G64', 0) ('G65', 0) ('G68', 0)\n",
      " ('G70', 0) ('G71', 0) ('G80', 0) ('G83', 0) ('G84', 0) ('G89', 0)\n",
      " ('G90', 0) ('G92', 0) ('G94', 0) ('G943', 0) ('G97', 0) ('G99', 0)\n",
      " ('G126', 0) ('G128', 0) ('G129', 0) ('G131', 0) ('G132', 0) ('G134', 0)\n",
      " ('G999', 0) ('G159', 0) ('G160', 0) ('G162', 0) ('G166', 0) ('G167', 0)\n",
      " ('G170', 0) ('G171', 0) ('G172', 0) ('G173', 0)]\n"
     ]
    }
   ],
   "source": [
    "# process the swiss codes\n",
    "# get child and parent codes:\n",
    "swiss_codes_parent = swiss_codes.loc[swiss_codes.parent_code == 'Parent code'].copy()\n",
    "swiss_codes_child = swiss_codes.loc[swiss_codes.parent_code != 'Parent code'].copy()\n",
    "\n",
    "# identify the codes that have actually been used:\n",
    "swiss_pcodes_used = swiss_surveys.code.unique()\n",
    "\n",
    "# make a list of the codes in use:\n",
    "scodes_used = swiss_codes.loc[swiss_codes.code.isin(swiss_pcodes_used)].copy()\n",
    "\n",
    "def drop_bad_codes(x):\n",
    "    try:\n",
    "        the_x = int(x)\n",
    "    except:\n",
    "        the_x = 0\n",
    "    else:\n",
    "        pass     \n",
    "    finally:\n",
    "        return the_x \n",
    "\n",
    "scodes_used['ospar_id']=scodes_used.ospar_id.map(lambda x: drop_bad_codes(x))\n",
    "scodes_used['ospar_id'] = scodes_used['ospar_id'].astype('int')\n",
    "scodes_used['paired'] = list(zip(scodes_used.code, scodes_used.ospar_id))\n",
    "scodes_noospar = scodes_used[scodes_used.ospar_id == 0]\n",
    "scodes_ospar = scodes_used[scodes_used.ospar_id != 0]\n",
    "\n",
    "print(\"\"\"\n",
    "This is the mlw/ospar code list from the swiss codes.\\n\n",
    "OSPAR codes that could not be typed to 'int' were counted as 0.\\n\n",
    "Any code with an ospar value of 0 was excluded\\n\n",
    "\"\"\")\n",
    "print(scodes_ospar.paired.unique())\n",
    "print(F\"\\nThese are the mlw codes that do not have a valid OSPAR code from the swiss list:\\n\\n{scodes_noospar.paired.unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OSPAR-ID', 'Type-Code', 'Name', 'J-Code', 'G-Code', 'OSPAR Name'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_list.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'ospar_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e9fc1c15298f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjoint_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mjoint_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mospar_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoint_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mospar_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdrop_bad_codes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mjlmlw_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoint_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjoint_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlw_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/refactor_process/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'ospar_id'"
     ]
    }
   ],
   "source": [
    "# process the joint_list:\n",
    "# these columns names are outrageous:\n",
    "joint_list.rename(columns={'OSPAR-ID':'ospar_id','G-Code':'mlw_code'}, inplace=True)\n",
    "joint_list.fillna('0', inplace=True)\n",
    "\n",
    "joint_list.ospar_id = joint_list.ospar_id.map(lambda x: drop_bad_codes(x))\n",
    "\n",
    "jlmlw_only = joint_list[joint_list.mlw_code != '0'].copy()\n",
    "\n",
    "jlmlw_only['paired'] = list(zip( jlmlw_only.mlw_code,jlmlw_only.ospar_id))\n",
    "\n",
    "# make some code pairs\n",
    "jlistkeys = joint_list[['mlw_code','ospar_id']].copy()\n",
    "\n",
    "# set up a mapper:\n",
    "mlwkeyed = {x[1]:x[0] for x in list(jlmlw_only.paired.unique())}\n",
    "osparkeyed = {x[0]:x[0] for x in list(jlmlw_only.paired.unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlw codes are no greater than 4 characters and ospar no greater than three\n",
    "# remove and save any values that don't match that criteria\n",
    "\n",
    "a_paired_list = jlmlw_only.paired.unique()\n",
    "fails = []\n",
    "paired = []\n",
    "def check_length(x, paired, fails):\n",
    "    \n",
    "    xnot = len(x[0])\n",
    "    \n",
    "    if xnot > 4:\n",
    "        fails.append((x[0], int(x[1])))\n",
    "    else:\n",
    "        paired.append(x)\n",
    "        \n",
    "for a_pair in a_paired_list:\n",
    "    check_length(a_pair, paired, fails)\n",
    "\n",
    "print(\"\"\"\n",
    "This is the mlw/ospar code list from david fleet.\\n\n",
    "MlW codes that had a length greater than 4 were counted as 0.\\n\n",
    "OSPAR codes that could not be typed to 'int' were counted as 0.\\n\n",
    "Any code with a value of 0 was excluded\\n\n",
    "\"\"\")\n",
    "print(paired)\n",
    "print(F\"\\nThese are the mlw codes that did not match from davids list:\\n{fails}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codepaires_from_swiss_data = scodes_ospar['paired'].unique()\n",
    "codepairs_from_fleet_data = paired\n",
    "\n",
    "a_list_of_unique_pairs = list(set(codepaires_from_swiss_data) | set(codepairs_from_fleet_data))\n",
    "\n",
    "gcodes = [x[0] for x in a_list_of_unique_pairs]\n",
    "\n",
    "# check to see if there are any duplicate pairs mlw ==> ospar:\n",
    "\n",
    "instances = {}\n",
    "duplicates = []\n",
    "\n",
    "for x in gcodes:\n",
    "    if x not in instances:\n",
    "        instances[x] = 1\n",
    "    else:\n",
    "        if instances[x] == 1:\n",
    "            duplicates.append(x)\n",
    "        instances[x] += 1\n",
    "\n",
    "print(\"These codes have more than one ospar id attributed to them\\n\")\n",
    "print(duplicates)\n",
    "\n",
    "print(\"\\nThis is how they are attributed\\n\")\n",
    "print([x for x in a_list_of_unique_pairs if x[0] in duplicates])\n",
    "\n",
    "print(\"\\nThis is the number of different definitions\\n\")\n",
    "print({k:v for k,v in instances.items() if k in duplicates})\n",
    "\n",
    "print(\"\\nThis is the MLW definition for those codes:\\n\")\n",
    "print(swiss_codes_parent.loc[swiss_codes_parent.code.isin(duplicates)][['code', 'description']])\n",
    "\n",
    "print(\"\\nThis is how many times those mlw codes have been registered in the swiss data:\\n\")\n",
    "print(swiss_surveys[swiss_surveys.code.isin(duplicates)].groupby('code').quantity.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the correct definition for MLW codes that have many OSPAR ids.\n",
    "\n",
    "The EU is putting together a list of harmonized codes that makes it easier to switch between different systems. We will try and consult that list before making any hasty decisions.\n",
    "\n",
    "### Account for equivalencies for dutch child codes\n",
    "\n",
    "Both projects use a coding system for items of local concern (sub codes or child codes) we need to find each projects analog and use appropriate OSPAR code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## !!! refresh the data from the hammerdirt api here:\n",
    "\n",
    "# a = requests.get('https://mwshovel.pythonanywhere.com/api/surveys/daily-totals/code-totals/swiss/')\n",
    "# b = requests.get('https://mwshovel.pythonanywhere.com/api/list-of-beaches/swiss/')\n",
    "# c = requests.get('https://mwshovel.pythonanywhere.com/api/mlw-codes/list/')\n",
    "\n",
    "# # the surveys need to be unpacked:\n",
    "# swiss_surveys = ut.unpack_survey_results(a.json())\n",
    "# swiss_surveys = pd.DataFrame(swiss_surveys)\n",
    "\n",
    "# # adding location date column\n",
    "# swiss_surveys['loc_date'] = list(zip(swiss_surveys['location'], swiss_surveys['date']))\n",
    "\n",
    "# # hold the original\n",
    "# x = a.json()\n",
    "\n",
    "# print(\"survey columns\")\n",
    "# print(swiss_surveys.columns)\n",
    "\n",
    "# swiss_beaches = pd.DataFrame(b.json())\n",
    "# print(\"beach columns\")\n",
    "# print(swiss_beaches.columns)\n",
    "\n",
    "# print(\"code columns\")\n",
    "# swiss_codes = pd.DataFrame(c.json())\n",
    "# print(swiss_codes.columns)\n",
    "\n",
    "# swiss_surveys.to_csv(data+'/hammerdirt_data.csv')\n",
    "# swiss_beaches.to_csv(beaches+'/hammerdirt_beaches.csv')\n",
    "# swiss_codes.to_csv(codes+'/swiss_codes.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
