{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### general tenplate\n",
    "\n",
    "\n",
    "Fetches data from the local source and esyablishes the following variables:\n",
    "\n",
    "1. dutch_codes\n",
    "2. swiss_codes\n",
    "3. dutch_surveys\n",
    "4. swiss_surveys\n",
    "5. swiss_beaches\n",
    "\n",
    "\n",
    "Establishes directory variables for fetching and putting to all subdirectories:\n",
    "\n",
    "1. data\n",
    "2. beaches\n",
    "3. codes\n",
    "4. geo\n",
    "5. output\n",
    "\n",
    "provides a script to update the remote data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# sys things\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# networks\n",
    "import requests\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "import resources.utilities.utility_functions as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look for resources here\n",
      "\n",
      "resources/surveydata resources/locationdata resources/mlwcodedefs resources/geodata output\n"
     ]
    }
   ],
   "source": [
    "# get folder extesions\n",
    "data, beaches, codes, geo, output=ut.make_local_paths()\n",
    "print(\"look for resources here\\n\")\n",
    "print(data, beaches, codes, geo, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# code data\n",
    "dutch_codes = pd.read_csv(codes+'/dutch_codes.csv')\n",
    "swiss_codes = pd.read_csv(codes+'/swiss_codes.csv')\n",
    "# this list was recieved from david fleet: one of the authors of the monitoring guide\n",
    "joint_list = pd.read_csv(F\"{codes}/jointcodes/fleetjcodes.csv\")\n",
    "\n",
    "# housekeeping\n",
    "dutch_codes.fillna(0, inplace=True)\n",
    "dutch_codes.rename(columns={'OSPAR_ID':'ospar_id', 'Description':'description'}, inplace=True)\n",
    "swiss_codes.rename(columns={'ospar_code':'ospar_id'}, inplace=True)\n",
    "swiss_codes.drop('Unnamed: 0', axis=1,inplace=True)\n",
    "\n",
    "# survey_data\n",
    "dutch_surveys = pd.read_csv(data+'/dataset_macrolitter_NL.csv')\n",
    "\n",
    "# use the aggregated hd data. This accounts for the custom codes used in Switzerland\n",
    "swiss_surveys = pd.read_csv(data+'/aggregated_hd_surveys.csv')\n",
    "\n",
    "# location data\n",
    "swiss_beaches = pd.read_csv(beaches+'/hammerdirt_beaches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns from cleaned up dutch data\n",
      "\n",
      "Index(['ID', 'description', 'category', 'ospar_id'], dtype='object')\n",
      "\n",
      "Columns from cleaned up dutch data\n",
      "\n",
      "Index(['code', 'material', 'description', 'source', 'source_two',\n",
      "       'source_three', 'parent_code', 'direct', 'single_use', 'micro',\n",
      "       'ospar_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns from cleaned up dutch data\\n\")\n",
    "print(dutch_codes.columns)\n",
    "\n",
    "print(\"\\nColumns from cleaned up dutch data\\n\")\n",
    "print(swiss_codes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_codes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# process the ducth codes:\n",
    "# identify codes that are common to both 'ospar_id' columns\n",
    "dutch_codes['parent_code'] = dutch_codes.ospar_id.round(0)\n",
    "dutch_codes['parent_code'] = dutch_codes['parent_code'].astype('int') \n",
    "dutch_codes['child_code'] = dutch_codes.ospar_id - dutch_codes.parent_code\n",
    "\n",
    "\n",
    "# the number of child codes:\n",
    "child_codes = dutch_codes.loc[dutch_codes.child_code > 0]\n",
    "ccodes = child_codes.parent_code.unique()\n",
    "\n",
    "# all the codes with no remainder:\n",
    "parent_codes = dutch_codes.loc[dutch_codes.child_code == 0]\n",
    "pcodes = parent_codes.parent_code.unique()\n",
    "\n",
    "# all the dutch codes that are not child codes:\n",
    "dcodesall = dutch_codes.parent_code.unique()\n",
    "\n",
    "print(\"\"\"\n",
    "This is the OSPAR code list from the dutch data.\\n\n",
    "OSPAR codes that could not be typed to 'int' were counted as 0.\\n\n",
    "Any code with an ospar value of 0 was excluded\\n\n",
    "\"\"\")\n",
    "print(dutch_codes['parent_code'].unique())\n",
    "print(F\"\\nThese are the detail codes used to better define the object:\\n\\n{ccodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# process the swiss codes\n",
    "# get child and parent codes:\n",
    "swiss_codes_parent = swiss_codes.loc[swiss_codes.parent_code == 'Parent code'].copy()\n",
    "swiss_codes_child = swiss_codes.loc[swiss_codes.parent_code != 'Parent code'].copy()\n",
    "\n",
    "# identify the codes that have actually been used:\n",
    "swiss_pcodes_used = swiss_surveys.code.unique()\n",
    "\n",
    "# make a list of the codes in use:\n",
    "scodes_used = swiss_codes.loc[swiss_codes.code.isin(swiss_pcodes_used)].copy()\n",
    "\n",
    "def drop_bad_codes(x):\n",
    "    try:\n",
    "        the_x = int(x)\n",
    "    except:\n",
    "        the_x = 0\n",
    "    else:\n",
    "        pass     \n",
    "    finally:\n",
    "        return the_x \n",
    "\n",
    "scodes_used['ospar_id']=scodes_used.ospar_id.map(lambda x: drop_bad_codes(x))\n",
    "scodes_used['ospar_id'] = scodes_used['ospar_id'].astype('int')\n",
    "scodes_used['paired'] = list(zip(scodes_used.code, scodes_used.ospar_id))\n",
    "scodes_noospar = scodes_used[scodes_used.ospar_id == 0]\n",
    "scodes_ospar = scodes_used[scodes_used.ospar_id != 0]\n",
    "\n",
    "print(\"\"\"\n",
    "This is the mlw/ospar code list from the swiss codes.\\n\n",
    "OSPAR codes that could not be typed to 'int' were counted as 0.\\n\n",
    "Any code with an ospar value of 0 was excluded\\n\n",
    "\"\"\")\n",
    "print(scodes_ospar.paired.unique())\n",
    "print(F\"\\nThese are the mlw codes that do not have a valid OSPAR code from the swiss list:\\n\\n{scodes_noospar.paired.unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# process the joint_list:\n",
    "# these columns names are outrageous:\n",
    "joint_list.rename(columns={'TSG_ML General- Code Guidance on Monitoring 2013.2':'mlw_code','OSPAR- Code':'ospar_id'}, inplace=True)\n",
    "joint_list.fillna('0', inplace=True)\n",
    "\n",
    "joint_list.ospar_id = joint_list.ospar_id.map(lambda x: drop_bad_codes(x))\n",
    "\n",
    "jlmlw_only = joint_list[joint_list.mlw_code != '0'].copy()\n",
    "\n",
    "jlmlw_only['paired'] = list(zip( jlmlw_only.mlw_code,jlmlw_only.ospar_id))\n",
    "\n",
    "# make some code pairs\n",
    "jlistkeys = joint_list[['mlw_code','ospar_id']].copy()\n",
    "\n",
    "# set up a mapper:\n",
    "mlwkeyed = {x[1]:x[0] for x in list(jlmlw_only.paired.unique())}\n",
    "osparkeyed = {x[0]:x[0] for x in list(jlmlw_only.paired.unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# mlw codes are no greater than 4 characters and ospar no greater than three\n",
    "# remove and save any values that don't match that criteria\n",
    "\n",
    "a_paired_list = jlmlw_only.paired.unique()\n",
    "fails = []\n",
    "paired = []\n",
    "def check_length(x, paired, fails):\n",
    "    \n",
    "    xnot = len(x[0])\n",
    "    \n",
    "    if xnot > 4:\n",
    "        fails.append((x[0], int(x[1])))\n",
    "    else:\n",
    "        paired.append(x)\n",
    "        \n",
    "for a_pair in a_paired_list:\n",
    "    check_length(a_pair, paired, fails)\n",
    "\n",
    "print(\"\"\"\n",
    "This is the mlw/ospar code list from david fleet.\\n\n",
    "MlW codes that had a length greater than 4 were counted as 0.\\n\n",
    "OSPAR codes that could not be typed to 'int' were counted as 0.\\n\n",
    "Any code with a value of 0 was excluded\\n\n",
    "\"\"\")\n",
    "print(paired)\n",
    "print(F\"\\nThese are the mlw codes that did not match from davids list:\\n{fails}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "codepaires_from_swiss_data = scodes_ospar['paired'].unique()\n",
    "codepairs_from_fleet_data = paired\n",
    "\n",
    "a_list_of_unique_pairs = list(set(codepaires_from_swiss_data) | set(codepairs_from_fleet_data))\n",
    "\n",
    "gcodes = [x[0] for x in a_list_of_unique_pairs]\n",
    "\n",
    "# check to see if there are any duplicate pairs mlw ==> ospar:\n",
    "\n",
    "instances = {}\n",
    "duplicates = []\n",
    "\n",
    "for x in gcodes:\n",
    "    if x not in instances:\n",
    "        instances[x] = 1\n",
    "    else:\n",
    "        if instances[x] == 1:\n",
    "            duplicates.append(x)\n",
    "        instances[x] += 1\n",
    "\n",
    "print(\"These codes have more than one ospar id attributed to them\\n\")\n",
    "print(duplicates)\n",
    "\n",
    "print(\"\\nThis is how they are attributed\\n\")\n",
    "print([x for x in a_list_of_unique_pairs if x[0] in duplicates])\n",
    "\n",
    "print(\"\\nThis is the number of different definitions\\n\")\n",
    "print({k:v for k,v in instances.items() if k in duplicates})\n",
    "\n",
    "print(\"\\nThis is the MLW definition for those codes:\\n\")\n",
    "print(swiss_codes_parent.loc[swiss_codes_parent.code.isin(duplicates)][['code', 'description']])\n",
    "\n",
    "print(\"\\nThis is how many times those mlw codes have been registered in the swiss data:\\n\")\n",
    "print(swiss_surveys[swiss_surveys.code.isin(duplicates)].groupby('code').quantity.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the correct definition for MLW codes that have many OSPAR ids.\n",
    "\n",
    "The EU is putting together a list of harmonized codes that makes it easier to switch between different systems. We will try and consult that list before making any hasty decisions.\n",
    "\n",
    "### Account for equivalencies for dutch child codes\n",
    "\n",
    "Both projects use a coding system for items of local concern (sub codes or child codes) we need to find each projects analog and use appropriate OSPAR code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## !!! refresh the data from the hammerdirt api here:\n",
    "\n",
    "# a = requests.get('https://mwshovel.pythonanywhere.com/api/surveys/daily-totals/code-totals/swiss/')\n",
    "# b = requests.get('https://mwshovel.pythonanywhere.com/api/list-of-beaches/swiss/')\n",
    "# c = requests.get('https://mwshovel.pythonanywhere.com/api/mlw-codes/list/')\n",
    "\n",
    "# # the surveys need to be unpacked:\n",
    "# swiss_surveys = ut.unpack_survey_results(a.json())\n",
    "# swiss_surveys = pd.DataFrame(swiss_surveys)\n",
    "\n",
    "# # adding location date column\n",
    "# swiss_surveys['loc_date'] = list(zip(swiss_surveys['location'], swiss_surveys['date']))\n",
    "\n",
    "# # hold the original\n",
    "# x = a.json()\n",
    "\n",
    "# print(\"survey columns\")\n",
    "# print(swiss_surveys.columns)\n",
    "\n",
    "# swiss_beaches = pd.DataFrame(b.json())\n",
    "# print(\"beach columns\")\n",
    "# print(swiss_beaches.columns)\n",
    "\n",
    "# print(\"code columns\")\n",
    "# swiss_codes = pd.DataFrame(c.json())\n",
    "# print(swiss_codes.columns)\n",
    "\n",
    "# swiss_surveys.to_csv(data+'/hammerdirt_data.csv')\n",
    "# swiss_beaches.to_csv(beaches+'/hammerdirt_beaches.csv')\n",
    "# swiss_codes.to_csv(codes+'/swiss_codes.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
