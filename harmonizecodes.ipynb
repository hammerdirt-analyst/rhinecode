{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### general tenplate\n",
    "\n",
    "\n",
    "Fetches data from the local source and esyablishes the following variables:\n",
    "\n",
    "1. dutch_codes\n",
    "2. swiss_codes\n",
    "3. dutch_surveys\n",
    "4. swiss_surveys\n",
    "5. swiss_beaches\n",
    "\n",
    "\n",
    "Establishes directory variables for fetching and putting to all subdirectories:\n",
    "\n",
    "1. data\n",
    "2. beaches\n",
    "3. codes\n",
    "4. geo\n",
    "5. output\n",
    "\n",
    "provides a script to update the remote data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys things\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# networks\n",
    "import requests\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "import resources.utilities.utility_functions as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resources/surveydata resources/locationdata resources/mlwcodedefs resources/geodata output\n"
     ]
    }
   ],
   "source": [
    "# get folder extesions\n",
    "data, beaches, codes, geo, output=ut.make_local_paths()\n",
    "print(data, beaches, codes, geo, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code data\n",
    "dutch_codes = pd.read_csv(codes+'/dutch_codes.csv')\n",
    "swiss_codes = pd.read_csv(codes+'/swiss_codes.csv')\n",
    "\n",
    "# housekeeping\n",
    "dutch_codes.fillna(0, inplace=True)\n",
    "dutch_codes.rename(columns={'OSPAR_ID':'ospar_id', 'Description':'description'}, inplace=True)\n",
    "swiss_codes.rename(columns={'ospar_code':'ospar_id'}, inplace=True)\n",
    "\n",
    "# survey_data\n",
    "dutch_surveys = pd.read_csv(data+'/dataset_macrolitter_NL.csv')\n",
    "\n",
    "# use the aggregated hd data. This accounts for the custom codes used in Switzerland\n",
    "swiss_surveys = pd.read_csv(data+'/aggregated_hd_surveys.csv')\n",
    "\n",
    "# location data\n",
    "swiss_beaches = pd.read_csv(beaches+'/hammerdirt_beaches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the ducth codes:\n",
    "# identify codes that are common to both 'ospar_id' columns\n",
    "dutch_codes['parent_code'] = dutch_codes.ospar_id.round(0)\n",
    "dutch_codes['child_code'] = dutch_codes.ospar_id - dutch_codes.parent_code\n",
    "\n",
    "# the number of child codes:\n",
    "child_codes = dutch_codes.loc[dutch_codes.child_code > 0]\n",
    "ccodes = child_codes.parent_code.unique()\n",
    "\n",
    "# all the codes with no remainder:\n",
    "parent_codes = dutch_codes.loc[dutch_codes.child_code == 0]\n",
    "pcodes = parent_codes.parent_code.unique()\n",
    "\n",
    "# all the dutch codes that are not child codes:\n",
    "dcodesall = dutch_codes.parent_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<class 'int'> <class 'numpy.int64'>\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# process the swiss codes\n",
    "# get child and parent codes:\n",
    "swiss_codes_parent = swiss_codes.loc[swiss_codes.parent_code == 'Parent code']\n",
    "swiss_codes_child = swiss_codes.loc[swiss_codes.parent_code != 'Parent code']\n",
    "\n",
    "# identify the codes that have actually been used:\n",
    "swiss_pcodes_used = swiss_surveys.code.unique()\n",
    "\n",
    "# make a list of the codes in use:\n",
    "scodes_used = swiss_codes.loc[swiss_codes.code.isin(swiss_pcodes_used)].copy()\n",
    "scodesu = scodes_used.ospar_id.unique()\n",
    "\n",
    "def drop_bad_codes(x):\n",
    "    try:\n",
    "        the_x = int(x)\n",
    "    except:\n",
    "        the_x = 0\n",
    "    else:\n",
    "        pass     \n",
    "    finally:\n",
    "        return the_x \n",
    "\n",
    "fixed_swiss_codes = list(set([drop_bad_codes(x) for x in scodesu]))\n",
    "scodes_used['ospar_id']=scodes_used.ospar_id.map(lambda x: drop_bad_codes(x))\n",
    "scodesu = scodes_used.ospar_id.unique().astype('int')\n",
    "\n",
    "# make sur they match\n",
    "\n",
    "# check length\n",
    "print(len(fixed_swiss_codes) ==  len(scodesu))\n",
    "\n",
    "# check types\n",
    "print(type(fixed_swiss_codes[0]), type(scodesu[0]))\n",
    "\n",
    "# check the symmetric difference:\n",
    "print(list(set(fixed_swiss_codes) ^ set(scodesu)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ospar codes from the swiss data unaccounted for\n",
      "\n",
      "[0, 12, 23, 45, 181, 56, 94, 96, 111, 114, 118]\n",
      "\n",
      "\n",
      "The MLW codes unaccounted for\n",
      "\n",
      "['G213' 'G214' 'G136' 'G139' 'G140' 'G142' 'G143' 'G202' 'G203' 'G204'\n",
      " 'G205' 'G208' 'G210' 'G174' 'G179' 'G180' 'G185' 'G186' 'G190' 'G191'\n",
      " 'G193' 'G195' 'G197' 'G198' 'G199' 'G146' 'G147' 'G148' 'G149' 'G150'\n",
      " 'G154' 'G156' 'G157' 'G158' 'G101' 'G102' 'G103' 'G104' 'G105' 'G106'\n",
      " 'G107' 'G108' 'G109' 'G111' 'G112' 'G113' 'G114' 'G115' 'G116' 'G117'\n",
      " 'G118' 'G119' 'G122' 'G123' 'G124' 'G13' 'G14' 'G17' 'G19' 'G2' 'G23'\n",
      " 'G36' 'G37' 'G39' 'G43' 'G48' 'G49' 'G5' 'G50' 'G52' 'G53' 'G55' 'G56'\n",
      " 'G59' 'G60' 'G61' 'G62' 'G63' 'G64' 'G65' 'G68' 'G70' 'G71' 'G73' 'G74'\n",
      " 'G80' 'G83' 'G84' 'G89' 'G90' 'G92' 'G94' 'G943' 'G97' 'G99' 'G126'\n",
      " 'G128' 'G129' 'G131' 'G132' 'G134' 'G999' 'G159' 'G160' 'G162' 'G166'\n",
      " 'G167' 'G170' 'G171' 'G172' 'G173']\n",
      "\n",
      "Defining the unaccounted ospar codes will reduce the above list to zero\n"
     ]
    }
   ],
   "source": [
    "# codes in swisscode not in dutch codes:\n",
    "noncodes = [x for x in fixed_swiss_codes if x not in dcodesall]\n",
    "\n",
    "print(\"The ospar codes from the swiss data unaccounted for\\n\")\n",
    "print(noncodes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# code defininitions for noncodes:\n",
    "noncodesdf = scodes_used.loc[scodes_used.ospar_id.isin(noncodes)]\n",
    "\n",
    "# mlw codes not accounted for:\n",
    "print(\"The the MLW codes unaccounted for\\n\")\n",
    "print(noncodesdf.code.unique())\n",
    "print(\"\\nDefining the unaccounted ospar codes will reduce the above list to zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## !!! refresh the data from the hammerdirt api here:\n",
    "\n",
    "# a = requests.get('https://mwshovel.pythonanywhere.com/api/surveys/daily-totals/code-totals/swiss/')\n",
    "# b = requests.get('https://mwshovel.pythonanywhere.com/api/list-of-beaches/swiss/')\n",
    "# c = requests.get('https://mwshovel.pythonanywhere.com/api/mlw-codes/list/')\n",
    "\n",
    "# # the surveys need to be unpacked:\n",
    "# swiss_surveys = ut.unpack_survey_results(a.json())\n",
    "# swiss_surveys = pd.DataFrame(swiss_surveys)\n",
    "\n",
    "# # adding location date column\n",
    "# swiss_surveys['loc_date'] = list(zip(swiss_surveys['location'], swiss_surveys['date']))\n",
    "\n",
    "# # hold the original\n",
    "# x = a.json()\n",
    "\n",
    "# print(\"survey columns\")\n",
    "# print(swiss_surveys.columns)\n",
    "\n",
    "# swiss_beaches = pd.DataFrame(b.json())\n",
    "# print(\"beach columns\")\n",
    "# print(swiss_beaches.columns)\n",
    "\n",
    "# print(\"code columns\")\n",
    "# swiss_codes = pd.DataFrame(c.json())\n",
    "# print(swiss_codes.columns)\n",
    "\n",
    "# swiss_surveys.to_csv(data+'/hammerdirt_data.csv')\n",
    "# swiss_beaches.to_csv(beaches+'/hammerdirt_beaches.csv')\n",
    "# swiss_codes.to_csv(codes+'/swiss_codes.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
