{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### general tenplate\n",
    "\n",
    "\n",
    "Fetches data from the local source and esyablishes the following variables:\n",
    "\n",
    "1. dutch_codes\n",
    "2. swiss_codes\n",
    "3. dutch_surveys\n",
    "4. swiss_surveys\n",
    "5. swiss_beaches\n",
    "\n",
    "\n",
    "Establishes directory variables for fetching and putting to all subdirectories:\n",
    "\n",
    "1. data\n",
    "2. beaches\n",
    "3. codes\n",
    "4. geo\n",
    "5. output\n",
    "\n",
    "provides a script to update the remote data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# sys things\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# networks\n",
    "import requests\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "import resources.utilities.utility_functions as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look for resources here\n",
      "\n",
      "resources/surveydata resources/locationdata resources/mlwcodedefs resources/geodata output\n"
     ]
    }
   ],
   "source": [
    "# get folder extesions\n",
    "data, beaches, codes, geo, output=ut.make_local_paths()\n",
    "print(\"look for resources here\\n\")\n",
    "print(data, beaches, codes, geo, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# code data\n",
    "dutch_codes = pd.read_csv(codes+'/dutch_codes.csv')\n",
    "swiss_codes = pd.read_csv(codes+'/swiss_codes.csv')\n",
    "# this list was recieved from david fleet: one of the authors of the monitoring guide\n",
    "joint_list = pd.read_csv(F\"{codes}/jointcodes/fleetjcodes.csv\")\n",
    "\n",
    "# housekeeping\n",
    "dutch_codes.fillna(0, inplace=True)\n",
    "dutch_codes.rename(columns={'OSPAR_ID':'ospar_id', 'Description':'description'}, inplace=True)\n",
    "swiss_codes.rename(columns={'ospar_code':'ospar_id'}, inplace=True)\n",
    "swiss_codes.drop('Unnamed: 0', axis=1,inplace=True)\n",
    "\n",
    "# survey_data\n",
    "dutch_surveys = pd.read_csv(data+'/dataset_macrolitter_NL.csv')\n",
    "\n",
    "# use the aggregated hd data. This accounts for the custom codes used in Switzerland\n",
    "swiss_surveys = pd.read_csv(data+'/aggregated_hd_surveys.csv')\n",
    "\n",
    "# location data\n",
    "swiss_beaches = pd.read_csv(beaches+'/hammerdirt_beaches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns from cleaned up dutch data\n",
      "\n",
      "Index(['ID', 'description', 'category', 'ospar_id'], dtype='object')\n",
      "\n",
      "Columns from cleaned up swiss data\n",
      "\n",
      "Index(['code', 'material', 'description', 'source', 'source_two',\n",
      "       'source_three', 'parent_code', 'direct', 'single_use', 'micro',\n",
      "       'ospar_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns from cleaned up dutch data\\n\")\n",
    "print(dutch_codes.columns)\n",
    "\n",
    "print(\"\\nColumns from cleaned up swiss data\\n\")\n",
    "print(swiss_codes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the OSPAR code list from the dutch data.\n",
      "\n",
      "OSPAR codes that could not be typed to 'int' were counted as 0.\n",
      "\n",
      "Any code with an ospar value of 0 was excluded\n",
      "\n",
      "\n",
      "[   1    2    3    4    5    6    7    9   10   13   14   15   16   20\n",
      "   21   24   25  113   31   32   33   36   38   40   42   43   44  117\n",
      "   46   48 1172  462   47   22   19  472  212  481   11   39    8   17\n",
      "   35   49   52   53   54   55   57   59   60   61   63   64   65   66\n",
      "   67   62   68   69   72   73   74   75   81   78   79   83   77   84\n",
      "   88   76   86   80   82  120   89   90   91   92   93   98  982  102\n",
      "   97   99   18  100  101  103  104  105]\n",
      "\n",
      "These are the detail codes used to better define the object:\n",
      "\n",
      "[  4 117  46   6  47  22  19   2  43  38  39  62  67  81 102   1]\n"
     ]
    }
   ],
   "source": [
    "# process the ducth codes:\n",
    "# identify codes that are common to both 'ospar_id' columns\n",
    "dutch_codes['parent_code'] = dutch_codes.ospar_id.round(0)\n",
    "dutch_codes['parent_code'] = dutch_codes['parent_code'].astype('int') \n",
    "dutch_codes['child_code'] = dutch_codes.ospar_id - dutch_codes.parent_code\n",
    "\n",
    "\n",
    "# the number of child codes:\n",
    "child_codes = dutch_codes.loc[dutch_codes.child_code > 0]\n",
    "ccodes = child_codes.parent_code.unique()\n",
    "\n",
    "# all the codes with no remainder:\n",
    "parent_codes = dutch_codes.loc[dutch_codes.child_code == 0]\n",
    "pcodes = parent_codes.parent_code.unique()\n",
    "\n",
    "# all the dutch codes that are not child codes:\n",
    "dcodesall = dutch_codes.parent_code.unique()\n",
    "\n",
    "print(\"\"\"\n",
    "This is the OSPAR code list from the dutch data.\\n\n",
    "OSPAR codes that could not be typed to 'int' were counted as 0.\\n\n",
    "Any code with an ospar value of 0 was excluded\\n\n",
    "\"\"\")\n",
    "print(dutch_codes['parent_code'].unique())\n",
    "print(F\"\\nThese are the detail codes used to better define the object:\\n\\n{ccodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the mlw/ospar code list from the swiss codes.\n",
      "\n",
      "OSPAR codes that could not be typed to 'int' were counted as 0.\n",
      "\n",
      "Any code with an ospar value of 0 was excluded\n",
      "\n",
      "\n",
      "[('G213', 181) ('G214', 111) ('G135', 54) ('G137', 54) ('G138', 57)\n",
      " ('G140', 56) ('G141', 55) ('G144', 100) ('G145', 59) ('G200', 91)\n",
      " ('G201', 93) ('G204', 94) ('G210', 96) ('G175', 78) ('G176', 82)\n",
      " ('G177', 81) ('G178', 77) ('G181', 89) ('G182', 80) ('G188', 89)\n",
      " ('G194', 89) ('G150', 118) ('G151', 62) ('G152', 63) ('G153', 67)\n",
      " ('G155', 67) ('G1', 1) ('G10', 6) ('G100', 103) ('G11', 7) ('G12', 7)\n",
      " ('G13', 12) ('G20', 15) ('G21', 15) ('G22', 15) ('G24', 15) ('G25', 48)\n",
      " ('G26', 16) ('G27', 64) ('G28', 17) ('G29', 18) ('G3', 2) ('G30', 19)\n",
      " ('G31', 19) ('G32', 20) ('G33', 21) ('G34', 22) ('G35', 22) ('G36', 23)\n",
      " ('G38', 40) ('G4', 3) ('G40', 25) ('G41', 113) ('G43', 114) ('G6', 11)\n",
      " ('G66', 39) ('G67', 40) ('G7', 4) ('G73', 45) ('G74', 45) ('G75', 117)\n",
      " ('G76', 46) ('G78', 117) ('G79', 46) ('G8', 4) ('G81', 117) ('G82', 46)\n",
      " ('G87', 48) ('G88', 48) ('G9', 5) ('G91', 91) ('G93', 48) ('G95', 98)\n",
      " ('G96', 99) ('G98', 102) ('G125', 49) ('G133', 97) ('G211', 105)\n",
      " ('G161', 69) ('G165', 72)]\n",
      "\n",
      "These are the mlw codes that do not have a valid OSPAR code from the swiss list:\n",
      "\n",
      "[('G136', 0) ('G139', 0) ('G142', 0) ('G143', 0) ('G202', 0) ('G203', 0)\n",
      " ('G205', 0) ('G208', 0) ('G174', 0) ('G179', 0) ('G180', 0) ('G185', 0)\n",
      " ('G186', 0) ('G190', 0) ('G191', 0) ('G193', 0) ('G195', 0) ('G197', 0)\n",
      " ('G198', 0) ('G199', 0) ('G146', 0) ('G147', 0) ('G148', 0) ('G149', 0)\n",
      " ('G154', 0) ('G156', 0) ('G157', 0) ('G158', 0) ('G101', 0) ('G102', 0)\n",
      " ('G103', 0) ('G104', 0) ('G105', 0) ('G106', 0) ('G107', 0) ('G108', 0)\n",
      " ('G109', 0) ('G111', 0) ('G112', 0) ('G113', 0) ('G114', 0) ('G115', 0)\n",
      " ('G116', 0) ('G117', 0) ('G118', 0) ('G119', 0) ('G122', 0) ('G123', 0)\n",
      " ('G124', 0) ('G14', 0) ('G17', 0) ('G19', 0) ('G2', 0) ('G23', 0)\n",
      " ('G37', 0) ('G39', 0) ('G48', 0) ('G49', 0) ('G5', 0) ('G50', 0)\n",
      " ('G52', 0) ('G53', 0) ('G55', 0) ('G56', 0) ('G59', 0) ('G60', 0)\n",
      " ('G61', 0) ('G62', 0) ('G63', 0) ('G64', 0) ('G65', 0) ('G68', 0)\n",
      " ('G70', 0) ('G71', 0) ('G80', 0) ('G83', 0) ('G84', 0) ('G89', 0)\n",
      " ('G90', 0) ('G92', 0) ('G94', 0) ('G943', 0) ('G97', 0) ('G99', 0)\n",
      " ('G126', 0) ('G128', 0) ('G129', 0) ('G131', 0) ('G132', 0) ('G134', 0)\n",
      " ('G999', 0) ('G159', 0) ('G160', 0) ('G162', 0) ('G166', 0) ('G167', 0)\n",
      " ('G170', 0) ('G171', 0) ('G172', 0) ('G173', 0)]\n"
     ]
    }
   ],
   "source": [
    "# process the swiss codes\n",
    "# get child and parent codes:\n",
    "swiss_codes_parent = swiss_codes.loc[swiss_codes.parent_code == 'Parent code'].copy()\n",
    "swiss_codes_child = swiss_codes.loc[swiss_codes.parent_code != 'Parent code'].copy()\n",
    "\n",
    "# identify the codes that have actually been used:\n",
    "swiss_pcodes_used = swiss_surveys.code.unique()\n",
    "\n",
    "# make a list of the codes in use:\n",
    "scodes_used = swiss_codes.loc[swiss_codes.code.isin(swiss_pcodes_used)].copy()\n",
    "\n",
    "def drop_bad_codes(x):\n",
    "    try:\n",
    "        the_x = int(x)\n",
    "    except:\n",
    "        the_x = 0\n",
    "    else:\n",
    "        pass     \n",
    "    finally:\n",
    "        return the_x \n",
    "\n",
    "scodes_used['ospar_id']=scodes_used.ospar_id.map(lambda x: drop_bad_codes(x))\n",
    "scodes_used['ospar_id'] = scodes_used['ospar_id'].astype('int')\n",
    "scodes_used['paired'] = list(zip(scodes_used.code, scodes_used.ospar_id))\n",
    "scodes_noospar = scodes_used[scodes_used.ospar_id == 0]\n",
    "scodes_ospar = scodes_used[scodes_used.ospar_id != 0]\n",
    "\n",
    "print(\"\"\"\n",
    "This is the mlw/ospar code list from the swiss codes.\\n\n",
    "OSPAR codes that could not be typed to 'int' were counted as 0.\\n\n",
    "Any code with an ospar value of 0 was excluded\\n\n",
    "\"\"\")\n",
    "print(scodes_ospar.paired.unique())\n",
    "print(F\"\\nThese are the mlw codes that do not have a valid OSPAR code from the swiss list:\\n\\n{scodes_noospar.paired.unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# process the joint_list:\n",
    "# these columns names are outrageous:\n",
    "joint_list.rename(columns={'TSG_ML General- Code Guidance on Monitoring 2013.2':'mlw_code','OSPAR- Code':'ospar_id'}, inplace=True)\n",
    "joint_list.fillna('0', inplace=True)\n",
    "\n",
    "joint_list.ospar_id = joint_list.ospar_id.map(lambda x: drop_bad_codes(x))\n",
    "\n",
    "jlmlw_only = joint_list[joint_list.mlw_code != '0'].copy()\n",
    "\n",
    "jlmlw_only['paired'] = list(zip( jlmlw_only.mlw_code,jlmlw_only.ospar_id))\n",
    "\n",
    "# make some code pairs\n",
    "jlistkeys = joint_list[['mlw_code','ospar_id']].copy()\n",
    "\n",
    "# set up a mapper:\n",
    "mlwkeyed = {x[1]:x[0] for x in list(jlmlw_only.paired.unique())}\n",
    "osparkeyed = {x[0]:x[0] for x in list(jlmlw_only.paired.unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the mlw/ospar code list from david fleet.\n",
      "\n",
      "MlW codes that had a length greater than 4 were counted as 0.\n",
      "\n",
      "OSPAR codes that could not be typed to 'int' were counted as 0.\n",
      "\n",
      "Any code with a value of 0 was excluded\n",
      "\n",
      "\n",
      "[('G89', 48), ('G90', 48), ('G39', 25), ('G39', 113), ('G92', 48), ('G59', 35), ('G52', 33), ('G52', 115), ('G52', 116), ('G61', 48), ('G42', 26), ('G60', 36), ('G44', 27), ('G70', 43), ('G211', 105), ('G100', 103), ('G99', 104), ('G2', 24), ('G2', 121), ('G2', 23), ('G2', 2), ('G2', 3), ('G2', 112), ('G6', 7), ('G6', 4), ('G6', 8), ('G6', 9), ('G6', 6), ('G6', 12), ('G6', 5), ('G6', 10), ('G6', 11), ('G84', 48), ('G38', 40), ('G1', 1), ('G20', 15), ('G18', 13), ('G66', 39), ('G95', 98), ('G98', 102), ('G97', 101), ('G86', 48), ('G32', 20), ('G91', 48), ('G64', 48), ('G26', 16), ('G25', 48), ('G27', 64), ('G68', 41), ('G73', 45), ('G124', 48), ('G65', 38), ('G93', 48), ('G29', 18), ('G87', 48), ('G166', 73), ('G28', 17), ('G43', 114), ('G88', 48), ('G72', 48), ('G19', 14), ('G137', 54), ('G140', 56), ('G139', 59), ('G145', 59), ('G141', 55), ('G143', 59), ('G204', 94), ('G207', 95), ('G203', 102), ('G200', 91), ('G201', 93), ('G210', 93), ('G194', 0), ('G182', 80), ('G184', 87), ('G181', 89), ('G186', 83), ('G177', 81), ('G179', 120), ('G197', 89), ('G197', 90), ('G191', 88), ('G180', 79), ('G195', 89), ('G193', 89), ('G153', 65), ('G153', 67), ('G149', 61), ('G149', 62), ('G149', 118), ('G149', 60), ('G95', 67), ('G155', 67), ('G149', 63), ('G156', 67), ('G158', 67), ('G154', 66), ('G163', 71), ('G164', 119), ('G165', 72), ('G159', 68), ('G162', 70), ('G160', 69), ('G167', 74), ('G173', 74), ('G173', 75), ('G133', 97), ('G125', 49), ('G126', 53), ('G134', 53), ('G131', 53)]\n",
      "\n",
      "These are the mlw codes that did not match from davids list:\n",
      "[('G218\\nglass or ceramic fragments >2.5cm', 0)]\n"
     ]
    }
   ],
   "source": [
    "# mlw codes are no greater than 4 characters and ospar no greater than three\n",
    "# remove and save any values that don't match that criteria\n",
    "\n",
    "a_paired_list = jlmlw_only.paired.unique()\n",
    "fails = []\n",
    "paired = []\n",
    "def check_length(x, paired, fails):\n",
    "    \n",
    "    xnot = len(x[0])\n",
    "    \n",
    "    if xnot > 4:\n",
    "        fails.append((x[0], int(x[1])))\n",
    "    else:\n",
    "        paired.append(x)\n",
    "        \n",
    "for a_pair in a_paired_list:\n",
    "    check_length(a_pair, paired, fails)\n",
    "\n",
    "print(\"\"\"\n",
    "This is the mlw/ospar code list from david fleet.\\n\n",
    "MlW codes that had a length greater than 4 were counted as 0.\\n\n",
    "OSPAR codes that could not be typed to 'int' were counted as 0.\\n\n",
    "Any code with a value of 0 was excluded\\n\n",
    "\"\"\")\n",
    "print(paired)\n",
    "print(F\"\\nThese are the mlw codes that did not match from davids list:\\n{fails}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These codes have more than one ospar id attributed to them\n",
      "\n",
      "['G194', 'G6', 'G149', 'G2', 'G173', 'G52', 'G95', 'G153', 'G210', 'G91', 'G39', 'G197']\n",
      "\n",
      "This is how they are attributed\n",
      "\n",
      "[('G6', 11), ('G194', 89), ('G95', 67), ('G194', 0), ('G210', 93), ('G6', 4), ('G173', 75), ('G149', 61), ('G2', 3), ('G52', 116), ('G6', 6), ('G149', 118), ('G149', 63), ('G39', 113), ('G153', 65), ('G2', 23), ('G197', 90), ('G173', 74), ('G149', 60), ('G52', 33), ('G2', 112), ('G2', 2), ('G2', 121), ('G95', 98), ('G6', 8), ('G149', 62), ('G153', 67), ('G6', 10), ('G6', 12), ('G91', 48), ('G52', 115), ('G6', 5), ('G210', 96), ('G6', 7), ('G2', 24), ('G91', 91), ('G6', 9), ('G39', 25), ('G197', 89)]\n",
      "\n",
      "This is the number of different definitions\n",
      "\n",
      "{'G6': 9, 'G194': 2, 'G95': 2, 'G210': 2, 'G173': 2, 'G149': 5, 'G2': 6, 'G52': 3, 'G39': 2, 'G153': 2, 'G197': 2, 'G91': 2}\n",
      "\n",
      "This is the MLW definition for those codes:\n",
      "\n",
      "     code                                        description\n",
      "25   G210                                Other glass/ceramic\n",
      "48   G194  Cables, metal wire(s) often inside rubber or p...\n",
      "51   G197                                        Other metal\n",
      "62   G149                                    Paper packaging\n",
      "66   G153            Cups, food containers, wrappers (paper)\n",
      "109    G2                                               Bags\n",
      "130   G39                                             Gloves\n",
      "145   G52                                    Nets and pieces\n",
      "153    G6     Bottles and containers, plastic non food/drink\n",
      "195   G91                                     Biomass holder\n",
      "225   G95                             Cotton bud/swab sticks\n",
      "258  G173                                              Other\n",
      "\n",
      "This is how many times those mlw codes have been registered in the swiss data:\n",
      "\n",
      "code\n",
      "G149      70\n",
      "G153     438\n",
      "G173       1\n",
      "G194     132\n",
      "G197      31\n",
      "G2        29\n",
      "G210     190\n",
      "G39        1\n",
      "G52       37\n",
      "G6        24\n",
      "G91      490\n",
      "G95     4482\n",
      "Name: quantity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "codepaires_from_swiss_data = scodes_ospar['paired'].unique()\n",
    "codepairs_from_fleet_data = paired\n",
    "\n",
    "a_list_of_unique_pairs = list(set(codepaires_from_swiss_data) | set(codepairs_from_fleet_data))\n",
    "\n",
    "gcodes = [x[0] for x in a_list_of_unique_pairs]\n",
    "\n",
    "# check to see if there are any duplicate pairs mlw ==> ospar:\n",
    "\n",
    "instances = {}\n",
    "duplicates = []\n",
    "\n",
    "for x in gcodes:\n",
    "    if x not in instances:\n",
    "        instances[x] = 1\n",
    "    else:\n",
    "        if instances[x] == 1:\n",
    "            duplicates.append(x)\n",
    "        instances[x] += 1\n",
    "\n",
    "print(\"These codes have more than one ospar id attributed to them\\n\")\n",
    "print(duplicates)\n",
    "\n",
    "print(\"\\nThis is how they are attributed\\n\")\n",
    "print([x for x in a_list_of_unique_pairs if x[0] in duplicates])\n",
    "\n",
    "print(\"\\nThis is the number of different definitions\\n\")\n",
    "print({k:v for k,v in instances.items() if k in duplicates})\n",
    "\n",
    "print(\"\\nThis is the MLW definition for those codes:\\n\")\n",
    "print(swiss_codes_parent.loc[swiss_codes_parent.code.isin(duplicates)][['code', 'description']])\n",
    "\n",
    "print(\"\\nThis is how many times those mlw codes have been registered in the swiss data:\\n\")\n",
    "print(swiss_surveys[swiss_surveys.code.isin(duplicates)].groupby('code').quantity.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the correct definition for MLW codes that have many OSPAR ids.\n",
    "\n",
    "The EU is putting together a list of harmonized codes that makes it easier to switch between different systems. We will try and consult that list before making any hasty decisions.\n",
    "\n",
    "### Account for equivalencies for dutch child codes\n",
    "\n",
    "Both projects use a coding system for items of local concern (sub codes or child codes) we need to find each projects analog and use appropriate OSPAR code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## !!! refresh the data from the hammerdirt api here:\n",
    "\n",
    "# a = requests.get('https://mwshovel.pythonanywhere.com/api/surveys/daily-totals/code-totals/swiss/')\n",
    "# b = requests.get('https://mwshovel.pythonanywhere.com/api/list-of-beaches/swiss/')\n",
    "# c = requests.get('https://mwshovel.pythonanywhere.com/api/mlw-codes/list/')\n",
    "\n",
    "# # the surveys need to be unpacked:\n",
    "# swiss_surveys = ut.unpack_survey_results(a.json())\n",
    "# swiss_surveys = pd.DataFrame(swiss_surveys)\n",
    "\n",
    "# # adding location date column\n",
    "# swiss_surveys['loc_date'] = list(zip(swiss_surveys['location'], swiss_surveys['date']))\n",
    "\n",
    "# # hold the original\n",
    "# x = a.json()\n",
    "\n",
    "# print(\"survey columns\")\n",
    "# print(swiss_surveys.columns)\n",
    "\n",
    "# swiss_beaches = pd.DataFrame(b.json())\n",
    "# print(\"beach columns\")\n",
    "# print(swiss_beaches.columns)\n",
    "\n",
    "# print(\"code columns\")\n",
    "# swiss_codes = pd.DataFrame(c.json())\n",
    "# print(swiss_codes.columns)\n",
    "\n",
    "# swiss_surveys.to_csv(data+'/hammerdirt_data.csv')\n",
    "# swiss_beaches.to_csv(beaches+'/hammerdirt_beaches.csv')\n",
    "# swiss_codes.to_csv(codes+'/swiss_codes.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
