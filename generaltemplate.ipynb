{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### general tenplate\n",
    "\n",
    "\n",
    "Fetches data from the local source and the following variables:\n",
    "\n",
    "1. dutch_codes\n",
    "2. swiss_codes\n",
    "3. dutch_surveys\n",
    "4. swiss_surveys\n",
    "5. swiss_beaches\n",
    "\n",
    "\n",
    "Establishes directory variables for fetching and putting to all subdirectories:\n",
    "\n",
    "1. data\n",
    "2. beaches\n",
    "3. codes\n",
    "4. geo\n",
    "5. output\n",
    "\n",
    "provides a script to update the remote data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys things\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# networks\n",
    "import requests\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "import resources.utilities.utility_functions as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resources/surveydata resources/locationdata resources/mlwcodedefs resources/geodata output\n"
     ]
    }
   ],
   "source": [
    "# get folder extesions\n",
    "data, beaches, codes, geo, output=ut.make_local_paths()\n",
    "print(data, beaches, codes, geo, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code data local\n",
    "dutch_codes = pd.read_csv(codes+'/dutch_codes.csv')\n",
    "swiss_codes = pd.read_csv(codes+'/swiss_codes.csv')\n",
    "\n",
    "# survey_data\n",
    "dutch_surveys = pd.read_csv(data+'/dataset_macrolitter_NL.csv')\n",
    "swiss_surveys = pd.read_csv(data+'/hammerdirt_data.csv')\n",
    "\n",
    "# location data\n",
    "swiss_beaches = pd.read_csv(beaches+'/hammerdirt_beaches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## !!! refresh the data from the hammerdirt api here:\n",
    "\n",
    "# a = requests.get('https://mwshovel.pythonanywhere.com/api/surveys/daily-totals/code-totals/swiss/')\n",
    "# b = requests.get('https://mwshovel.pythonanywhere.com/api/list-of-beaches/swiss/')\n",
    "# c = requests.get('https://mwshovel.pythonanywhere.com/api/mlw-codes/list/')\n",
    "\n",
    "# # the surveys need to be unpacked:\n",
    "# swiss_surveys = ut.unpack_survey_results(a.json())\n",
    "# swiss_surveys = pd.DataFrame(swiss_surveys)\n",
    "\n",
    "# # adding location date column\n",
    "# swiss_surveys['loc_date'] = list(zip(swiss_surveys['location'], swiss_surveys['date']))\n",
    "\n",
    "# # hold the original\n",
    "# x = a.json()\n",
    "\n",
    "# print(\"survey columns\")\n",
    "# print(swiss_surveys.columns)\n",
    "\n",
    "# swiss_beaches = pd.DataFrame(b.json())\n",
    "# print(\"beach columns\")\n",
    "# print(swiss_beaches.columns)\n",
    "\n",
    "# print(\"code columns\")\n",
    "# swiss_codes = pd.DataFrame(c.json())\n",
    "# print(swiss_codes.columns)\n",
    "\n",
    "# swiss_surveys.to_csv(data+'/hammerdirt_data.csv')\n",
    "# swiss_beaches.to_csv(beaches+'/hammerdirt_beaches.csv')\n",
    "# swiss_codes.to_csv(codes+'/swiss_codes.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
